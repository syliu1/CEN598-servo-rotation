{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4faf209-5ce2-4a7a-9893-0a232c651529",
   "metadata": {},
   "source": [
    "WindowSize=5, 600epochs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a19aa44-6448-47b5-844f-d7ceeeee1313",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f265561f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.10.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.version.VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aae81f9f-1f51-468b-b0f6-b18bec3289fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#columns = [\"mic1\", \"mic2\", \"mic3\", \"mic4\", \"mic5\", \"angle\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2dd7e185-9212-4c69-8b60-e12baa633a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"C:/Users/hank4/Documents/CEN598-Final-Project/CEN598-servo-rotation-data-collection/Dataset/raw_combined_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e57a9d99-2512-4f56-8928-c4f650f3c9b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mic1</th>\n",
       "      <th>mic2</th>\n",
       "      <th>mic3</th>\n",
       "      <th>mic4</th>\n",
       "      <th>mic5</th>\n",
       "      <th>angle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18.03</td>\n",
       "      <td>19.49</td>\n",
       "      <td>15.27</td>\n",
       "      <td>16.39</td>\n",
       "      <td>17.49</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17.69</td>\n",
       "      <td>19.00</td>\n",
       "      <td>14.98</td>\n",
       "      <td>16.06</td>\n",
       "      <td>17.09</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17.49</td>\n",
       "      <td>18.61</td>\n",
       "      <td>14.62</td>\n",
       "      <td>15.85</td>\n",
       "      <td>16.78</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17.31</td>\n",
       "      <td>18.20</td>\n",
       "      <td>14.40</td>\n",
       "      <td>15.61</td>\n",
       "      <td>16.52</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16.99</td>\n",
       "      <td>17.76</td>\n",
       "      <td>14.28</td>\n",
       "      <td>15.30</td>\n",
       "      <td>16.09</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>16.68</td>\n",
       "      <td>17.44</td>\n",
       "      <td>14.17</td>\n",
       "      <td>15.13</td>\n",
       "      <td>15.60</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mic1   mic2   mic3   mic4   mic5 angle\n",
       "0  18.03  19.49  15.27  16.39  17.49     0\n",
       "1  17.69  19.00  14.98  16.06  17.09     0\n",
       "2  17.49  18.61  14.62  15.85  16.78     0\n",
       "3  17.31  18.20  14.40  15.61  16.52     0\n",
       "4  16.99  17.76  14.28  15.30  16.09     0\n",
       "5  16.68  17.44  14.17  15.13  15.60     0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "808e76df-c23b-4c0a-be9c-258b3b7024b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28000, 26)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "window_size = 5\n",
    "no_of_rows = int(len(df)/window_size)\n",
    "rows, cols = (no_of_rows, window_size)\n",
    "mic1_window = [[0 for i in range(cols)] for j in range(rows)]\n",
    "mic2_window = [[0 for i in range(cols)] for j in range(rows)]\n",
    "mic3_window = [[0 for i in range(cols)] for j in range(rows)]\n",
    "mic4_window = [[0 for i in range(cols)] for j in range(rows)]\n",
    "mic5_window = [[0 for i in range(cols)] for j in range(rows)]\n",
    "concatenated_window = [[0 for i in range((cols*5)+1)] for j in range(rows)]\n",
    "np.shape(concatenated_window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bc8e36ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['angle'] = df['angle'].map({'0':0, '36':1, '72':2, '108':3, '144':4, '180':5, 'silence':6})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4e2b7c2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['angle'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cd5e31fd-113b-4984-9400-ade72c17ba6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "k=-1\n",
    "for i in range(0, no_of_rows):\n",
    "    angle = 0\n",
    "    for j in range(0, window_size):\n",
    "        k=k+1\n",
    "        mic1_window[i][j] = df[\"mic1\"][k]\n",
    "        mic2_window[i][j] = df[\"mic2\"][k]\n",
    "        mic3_window[i][j] = df[\"mic3\"][k]\n",
    "        mic4_window[i][j] = df[\"mic4\"][k]\n",
    "        mic5_window[i][j] = df[\"mic5\"][k]\n",
    "        concatenated_window[i][j] = mic1_window[i][j]\n",
    "        concatenated_window[i][j+(window_size*1)] = mic2_window[i][j]\n",
    "        concatenated_window[i][j+(window_size*2)] = mic3_window[i][j]\n",
    "        concatenated_window[i][j+(window_size*3)] = mic4_window[i][j]\n",
    "        concatenated_window[i][j+(window_size*4)] = mic5_window[i][j]\n",
    "        angle = angle+df[\"angle\"][k]\n",
    "        #print(df[\"angle\"][k])\n",
    "    concatenated_window[i][j+(window_size*4)+1] = angle/window_size\n",
    "#print(mic1_window)\n",
    "#print(concatenated_window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "825cb25e-aebc-4c62-81f2-e8c33f8eaf42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28000"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(concatenated_window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "46c1ffd3-0ab0-4af8-b1e6-a1088dead985",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mic1-1'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i=1\n",
    "j=1\n",
    "\"mic\"+str(i)+\"-\"+str(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4b3e7498-3eed-4505-a3a9-c8970ce69d97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mic1-1', 'mic1-2', 'mic1-3', 'mic1-4', 'mic1-5', 'mic2-1', 'mic2-2', 'mic2-3', 'mic2-4', 'mic2-5', 'mic3-1', 'mic3-2', 'mic3-3', 'mic3-4', 'mic3-5', 'mic4-1', 'mic4-2', 'mic4-3', 'mic4-4', 'mic4-5', 'mic5-1', 'mic5-2', 'mic5-3', 'mic5-4', 'mic5-5', 'angle']\n"
     ]
    }
   ],
   "source": [
    "no_of_mics = 5\n",
    "columns = []\n",
    "for i in range(1, no_of_mics+1):\n",
    "    for j in range(1, cols+1):\n",
    "        columns.append(\"mic\"+str(i)+\"-\"+str(j)) \n",
    "columns.append(\"angle\")\n",
    "print(columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c55e5701-3c2b-4f63-97f6-33ff59f615b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(concatenated_window, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a7d95c0c-e1b9-4261-aaea-681ff52bb711",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mic1-1</th>\n",
       "      <td>28000.0</td>\n",
       "      <td>22.543157</td>\n",
       "      <td>5.351183</td>\n",
       "      <td>12.29</td>\n",
       "      <td>18.8700</td>\n",
       "      <td>22.140</td>\n",
       "      <td>25.6600</td>\n",
       "      <td>55.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mic1-2</th>\n",
       "      <td>28000.0</td>\n",
       "      <td>22.541234</td>\n",
       "      <td>5.351301</td>\n",
       "      <td>12.27</td>\n",
       "      <td>18.8675</td>\n",
       "      <td>22.150</td>\n",
       "      <td>25.6200</td>\n",
       "      <td>57.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mic1-3</th>\n",
       "      <td>28000.0</td>\n",
       "      <td>22.540370</td>\n",
       "      <td>5.350329</td>\n",
       "      <td>12.25</td>\n",
       "      <td>18.8800</td>\n",
       "      <td>22.180</td>\n",
       "      <td>25.6225</td>\n",
       "      <td>57.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mic1-4</th>\n",
       "      <td>28000.0</td>\n",
       "      <td>22.541517</td>\n",
       "      <td>5.350336</td>\n",
       "      <td>12.24</td>\n",
       "      <td>18.8800</td>\n",
       "      <td>22.140</td>\n",
       "      <td>25.6400</td>\n",
       "      <td>56.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mic1-5</th>\n",
       "      <td>28000.0</td>\n",
       "      <td>22.542809</td>\n",
       "      <td>5.350492</td>\n",
       "      <td>12.19</td>\n",
       "      <td>18.8900</td>\n",
       "      <td>22.140</td>\n",
       "      <td>25.6600</td>\n",
       "      <td>56.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mic2-1</th>\n",
       "      <td>28000.0</td>\n",
       "      <td>24.678552</td>\n",
       "      <td>6.787049</td>\n",
       "      <td>11.48</td>\n",
       "      <td>19.7700</td>\n",
       "      <td>23.770</td>\n",
       "      <td>28.3400</td>\n",
       "      <td>70.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mic2-2</th>\n",
       "      <td>28000.0</td>\n",
       "      <td>24.676283</td>\n",
       "      <td>6.786920</td>\n",
       "      <td>11.49</td>\n",
       "      <td>19.7100</td>\n",
       "      <td>23.780</td>\n",
       "      <td>28.3400</td>\n",
       "      <td>73.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mic2-3</th>\n",
       "      <td>28000.0</td>\n",
       "      <td>24.674641</td>\n",
       "      <td>6.785523</td>\n",
       "      <td>11.49</td>\n",
       "      <td>19.7300</td>\n",
       "      <td>23.770</td>\n",
       "      <td>28.3300</td>\n",
       "      <td>73.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mic2-4</th>\n",
       "      <td>28000.0</td>\n",
       "      <td>24.676320</td>\n",
       "      <td>6.785383</td>\n",
       "      <td>11.64</td>\n",
       "      <td>19.7375</td>\n",
       "      <td>23.770</td>\n",
       "      <td>28.3300</td>\n",
       "      <td>71.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mic2-5</th>\n",
       "      <td>28000.0</td>\n",
       "      <td>24.677734</td>\n",
       "      <td>6.784958</td>\n",
       "      <td>11.55</td>\n",
       "      <td>19.7600</td>\n",
       "      <td>23.780</td>\n",
       "      <td>28.3500</td>\n",
       "      <td>70.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mic3-1</th>\n",
       "      <td>28000.0</td>\n",
       "      <td>21.470664</td>\n",
       "      <td>6.144751</td>\n",
       "      <td>10.35</td>\n",
       "      <td>16.8575</td>\n",
       "      <td>20.380</td>\n",
       "      <td>24.6700</td>\n",
       "      <td>69.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mic3-2</th>\n",
       "      <td>28000.0</td>\n",
       "      <td>21.469364</td>\n",
       "      <td>6.145960</td>\n",
       "      <td>10.33</td>\n",
       "      <td>16.8475</td>\n",
       "      <td>20.390</td>\n",
       "      <td>24.6625</td>\n",
       "      <td>66.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mic3-3</th>\n",
       "      <td>28000.0</td>\n",
       "      <td>21.469409</td>\n",
       "      <td>6.146323</td>\n",
       "      <td>10.25</td>\n",
       "      <td>16.8500</td>\n",
       "      <td>20.395</td>\n",
       "      <td>24.6825</td>\n",
       "      <td>67.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mic3-4</th>\n",
       "      <td>28000.0</td>\n",
       "      <td>21.471171</td>\n",
       "      <td>6.146546</td>\n",
       "      <td>10.20</td>\n",
       "      <td>16.8300</td>\n",
       "      <td>20.390</td>\n",
       "      <td>24.7000</td>\n",
       "      <td>69.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mic3-5</th>\n",
       "      <td>28000.0</td>\n",
       "      <td>21.470686</td>\n",
       "      <td>6.145135</td>\n",
       "      <td>10.40</td>\n",
       "      <td>16.8600</td>\n",
       "      <td>20.380</td>\n",
       "      <td>24.6800</td>\n",
       "      <td>70.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mic4-1</th>\n",
       "      <td>28000.0</td>\n",
       "      <td>23.165404</td>\n",
       "      <td>7.237612</td>\n",
       "      <td>10.47</td>\n",
       "      <td>18.2275</td>\n",
       "      <td>22.240</td>\n",
       "      <td>26.8300</td>\n",
       "      <td>122.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mic4-2</th>\n",
       "      <td>28000.0</td>\n",
       "      <td>23.163750</td>\n",
       "      <td>7.239560</td>\n",
       "      <td>10.41</td>\n",
       "      <td>18.2100</td>\n",
       "      <td>22.230</td>\n",
       "      <td>26.8200</td>\n",
       "      <td>116.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mic4-3</th>\n",
       "      <td>28000.0</td>\n",
       "      <td>23.164062</td>\n",
       "      <td>7.239942</td>\n",
       "      <td>10.49</td>\n",
       "      <td>18.2000</td>\n",
       "      <td>22.250</td>\n",
       "      <td>26.8000</td>\n",
       "      <td>120.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mic4-4</th>\n",
       "      <td>28000.0</td>\n",
       "      <td>23.165947</td>\n",
       "      <td>7.240678</td>\n",
       "      <td>10.43</td>\n",
       "      <td>18.2000</td>\n",
       "      <td>22.280</td>\n",
       "      <td>26.8000</td>\n",
       "      <td>124.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mic4-5</th>\n",
       "      <td>28000.0</td>\n",
       "      <td>23.166148</td>\n",
       "      <td>7.238898</td>\n",
       "      <td>10.53</td>\n",
       "      <td>18.1800</td>\n",
       "      <td>22.250</td>\n",
       "      <td>26.8000</td>\n",
       "      <td>125.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mic5-1</th>\n",
       "      <td>28000.0</td>\n",
       "      <td>24.752798</td>\n",
       "      <td>8.632066</td>\n",
       "      <td>10.15</td>\n",
       "      <td>19.0500</td>\n",
       "      <td>24.100</td>\n",
       "      <td>29.2600</td>\n",
       "      <td>150.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mic5-2</th>\n",
       "      <td>28000.0</td>\n",
       "      <td>24.750306</td>\n",
       "      <td>8.632568</td>\n",
       "      <td>10.14</td>\n",
       "      <td>19.0400</td>\n",
       "      <td>24.100</td>\n",
       "      <td>29.2600</td>\n",
       "      <td>143.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mic5-3</th>\n",
       "      <td>28000.0</td>\n",
       "      <td>24.748740</td>\n",
       "      <td>8.631246</td>\n",
       "      <td>10.25</td>\n",
       "      <td>19.0800</td>\n",
       "      <td>24.100</td>\n",
       "      <td>29.2300</td>\n",
       "      <td>147.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mic5-4</th>\n",
       "      <td>28000.0</td>\n",
       "      <td>24.750718</td>\n",
       "      <td>8.631619</td>\n",
       "      <td>10.27</td>\n",
       "      <td>19.0600</td>\n",
       "      <td>24.120</td>\n",
       "      <td>29.2000</td>\n",
       "      <td>151.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mic5-5</th>\n",
       "      <td>28000.0</td>\n",
       "      <td>24.752753</td>\n",
       "      <td>8.631443</td>\n",
       "      <td>10.25</td>\n",
       "      <td>19.0500</td>\n",
       "      <td>24.130</td>\n",
       "      <td>29.2200</td>\n",
       "      <td>153.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>angle</th>\n",
       "      <td>28000.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000036</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>5.0000</td>\n",
       "      <td>6.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          count       mean       std    min      25%     50%      75%     max\n",
       "mic1-1  28000.0  22.543157  5.351183  12.29  18.8700  22.140  25.6600   55.70\n",
       "mic1-2  28000.0  22.541234  5.351301  12.27  18.8675  22.150  25.6200   57.46\n",
       "mic1-3  28000.0  22.540370  5.350329  12.25  18.8800  22.180  25.6225   57.71\n",
       "mic1-4  28000.0  22.541517  5.350336  12.24  18.8800  22.140  25.6400   56.81\n",
       "mic1-5  28000.0  22.542809  5.350492  12.19  18.8900  22.140  25.6600   56.00\n",
       "mic2-1  28000.0  24.678552  6.787049  11.48  19.7700  23.770  28.3400   70.90\n",
       "mic2-2  28000.0  24.676283  6.786920  11.49  19.7100  23.780  28.3400   73.00\n",
       "mic2-3  28000.0  24.674641  6.785523  11.49  19.7300  23.770  28.3300   73.28\n",
       "mic2-4  28000.0  24.676320  6.785383  11.64  19.7375  23.770  28.3300   71.68\n",
       "mic2-5  28000.0  24.677734  6.784958  11.55  19.7600  23.780  28.3500   70.63\n",
       "mic3-1  28000.0  21.470664  6.144751  10.35  16.8575  20.380  24.6700   69.06\n",
       "mic3-2  28000.0  21.469364  6.145960  10.33  16.8475  20.390  24.6625   66.19\n",
       "mic3-3  28000.0  21.469409  6.146323  10.25  16.8500  20.395  24.6825   67.46\n",
       "mic3-4  28000.0  21.471171  6.146546  10.20  16.8300  20.390  24.7000   69.78\n",
       "mic3-5  28000.0  21.470686  6.145135  10.40  16.8600  20.380  24.6800   70.52\n",
       "mic4-1  28000.0  23.165404  7.237612  10.47  18.2275  22.240  26.8300  122.04\n",
       "mic4-2  28000.0  23.163750  7.239560  10.41  18.2100  22.230  26.8200  116.57\n",
       "mic4-3  28000.0  23.164062  7.239942  10.49  18.2000  22.250  26.8000  120.71\n",
       "mic4-4  28000.0  23.165947  7.240678  10.43  18.2000  22.280  26.8000  124.23\n",
       "mic4-5  28000.0  23.166148  7.238898  10.53  18.1800  22.250  26.8000  125.28\n",
       "mic5-1  28000.0  24.752798  8.632066  10.15  19.0500  24.100  29.2600  150.39\n",
       "mic5-2  28000.0  24.750306  8.632568  10.14  19.0400  24.100  29.2600  143.36\n",
       "mic5-3  28000.0  24.748740  8.631246  10.25  19.0800  24.100  29.2300  147.50\n",
       "mic5-4  28000.0  24.750718  8.631619  10.27  19.0600  24.120  29.2000  151.55\n",
       "mic5-5  28000.0  24.752753  8.631443  10.25  19.0500  24.130  29.2200  153.53\n",
       "angle   28000.0   3.000000  2.000036   0.00   1.0000   3.000   5.0000    6.00"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "60cfe9d3-0c2c-4f30-a70b-ac6656212810",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "16b580e2-2bc8-4dd4-96af-0d5f0677147e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('angle',axis=1).values\n",
    "y = df['angle'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9a20f3bd-2da6-4035-9092-7cd3ffccffb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b6c5cf22-55dc-4be7-bc9c-c16ed6e8a3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f2adc747-11e6-456a-b29f-0a3cc79992a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_cat_train = to_categorical(y_train,7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f9b9760c-87bf-4c71-a11f-4ff29de37ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_cat_test = to_categorical(y_test,7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1a79ff7e-44d7-43fa-b50e-4614183b4812",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "85c53710-755c-4628-b2c5-5ab6339543ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c9fee8e9-a48e-4afe-a761-33f8acc19a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaler.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "85004bab-6012-48f7-adac-196ead01d726",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train = scaler.transform(X_train)\n",
    "#X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "514d6a85-abf6-4305-b42a-2023ac17e1d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'print(\"min: \",scaler.min_)\\nprint(\"scale: \",scaler.scale_)\\nprint(\"data_min: \",scaler.data_min_)\\nprint(\"data_max: \",scaler.data_max_)\\nprint(\"n_features_in: \",scaler.n_features_in_)'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''print(\"min: \",scaler.min_)\n",
    "print(\"scale: \",scaler.scale_)\n",
    "print(\"data_min: \",scaler.data_min_)\n",
    "print(\"data_max: \",scaler.data_max_)\n",
    "print(\"n_features_in: \",scaler.n_features_in_)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0976aaa3-6036-440f-b46f-b364ebf9966d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train/1023.0\n",
    "X_test = X_test/1023.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "317ff52a-39f9-487a-8f7c-59e09fb6f339",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation,Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0e4f22a6-0689-4442-bfae-66b464fc881b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22400, 25)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "453bdf44-1b36-430a-aa16-c175f796f109",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# https://stats.stackexchange.com/questions/181/how-to-choose-the-number-of-hidden-layers-and-nodes-in-a-feedforward-neural-netw\n",
    "\n",
    "model.add(Dense(units=10,activation='relu'))\n",
    "model.add(Dense(units=32,activation='relu'))\n",
    "model.add(Dense(units=16,activation='relu'))\n",
    "\n",
    "model.add(Dense(units=7,activation='softmax'))\n",
    "\n",
    "# For a multi-class classification problem\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "27e24c7c-964b-4b24-bebf-cb4a9ed9af4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/600\n",
      "22/22 [==============================] - 1s 10ms/step - loss: 1.9454 - accuracy: 0.1488 - val_loss: 1.9447 - val_accuracy: 0.1366\n",
      "Epoch 2/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.9434 - accuracy: 0.1444 - val_loss: 1.9420 - val_accuracy: 0.1366\n",
      "Epoch 3/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.9394 - accuracy: 0.1370 - val_loss: 1.9353 - val_accuracy: 0.1612\n",
      "Epoch 4/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.9291 - accuracy: 0.1942 - val_loss: 1.9191 - val_accuracy: 0.2796\n",
      "Epoch 5/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.9084 - accuracy: 0.2853 - val_loss: 1.8899 - val_accuracy: 0.2900\n",
      "Epoch 6/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.8746 - accuracy: 0.2732 - val_loss: 1.8473 - val_accuracy: 0.2814\n",
      "Epoch 7/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.8309 - accuracy: 0.2702 - val_loss: 1.7968 - val_accuracy: 0.2759\n",
      "Epoch 8/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.7857 - accuracy: 0.2683 - val_loss: 1.7496 - val_accuracy: 0.2857\n",
      "Epoch 9/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.7447 - accuracy: 0.2761 - val_loss: 1.7072 - val_accuracy: 0.2907\n",
      "Epoch 10/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.7097 - accuracy: 0.2828 - val_loss: 1.6741 - val_accuracy: 0.2982\n",
      "Epoch 11/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.6814 - accuracy: 0.2884 - val_loss: 1.6476 - val_accuracy: 0.3054\n",
      "Epoch 12/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.6606 - accuracy: 0.2975 - val_loss: 1.6289 - val_accuracy: 0.3066\n",
      "Epoch 13/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.6452 - accuracy: 0.3048 - val_loss: 1.6157 - val_accuracy: 0.3182\n",
      "Epoch 14/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.6347 - accuracy: 0.3024 - val_loss: 1.6068 - val_accuracy: 0.3143\n",
      "Epoch 15/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.6276 - accuracy: 0.3048 - val_loss: 1.6001 - val_accuracy: 0.3220\n",
      "Epoch 16/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 1.6225 - accuracy: 0.3092 - val_loss: 1.5967 - val_accuracy: 0.3195\n",
      "Epoch 17/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.6182 - accuracy: 0.3091 - val_loss: 1.5927 - val_accuracy: 0.3152\n",
      "Epoch 18/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.6150 - accuracy: 0.3176 - val_loss: 1.5894 - val_accuracy: 0.3268\n",
      "Epoch 19/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.6122 - accuracy: 0.3150 - val_loss: 1.5865 - val_accuracy: 0.3429\n",
      "Epoch 20/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.6095 - accuracy: 0.3366 - val_loss: 1.5870 - val_accuracy: 0.3464\n",
      "Epoch 21/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 1.6077 - accuracy: 0.3160 - val_loss: 1.5809 - val_accuracy: 0.3502\n",
      "Epoch 22/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 1.6042 - accuracy: 0.3443 - val_loss: 1.5780 - val_accuracy: 0.3496\n",
      "Epoch 23/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.6003 - accuracy: 0.3586 - val_loss: 1.5739 - val_accuracy: 0.3700\n",
      "Epoch 24/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.5960 - accuracy: 0.3564 - val_loss: 1.5696 - val_accuracy: 0.3993\n",
      "Epoch 25/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.5900 - accuracy: 0.3911 - val_loss: 1.5634 - val_accuracy: 0.3963\n",
      "Epoch 26/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.5829 - accuracy: 0.3874 - val_loss: 1.5557 - val_accuracy: 0.4302\n",
      "Epoch 27/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.5734 - accuracy: 0.4226 - val_loss: 1.5446 - val_accuracy: 0.4487\n",
      "Epoch 28/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.5610 - accuracy: 0.4379 - val_loss: 1.5311 - val_accuracy: 0.4580\n",
      "Epoch 29/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.5456 - accuracy: 0.4437 - val_loss: 1.5133 - val_accuracy: 0.4534\n",
      "Epoch 30/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.5259 - accuracy: 0.4498 - val_loss: 1.4920 - val_accuracy: 0.4762\n",
      "Epoch 31/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.5012 - accuracy: 0.4526 - val_loss: 1.4667 - val_accuracy: 0.4709\n",
      "Epoch 32/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 1.4736 - accuracy: 0.4618 - val_loss: 1.4375 - val_accuracy: 0.4879\n",
      "Epoch 33/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.4437 - accuracy: 0.4676 - val_loss: 1.4079 - val_accuracy: 0.4873\n",
      "Epoch 34/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.4127 - accuracy: 0.4755 - val_loss: 1.3777 - val_accuracy: 0.4984\n",
      "Epoch 35/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.3813 - accuracy: 0.4772 - val_loss: 1.3461 - val_accuracy: 0.4989\n",
      "Epoch 36/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.3511 - accuracy: 0.4870 - val_loss: 1.3153 - val_accuracy: 0.5052\n",
      "Epoch 37/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.3221 - accuracy: 0.4904 - val_loss: 1.2879 - val_accuracy: 0.5170\n",
      "Epoch 38/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.2945 - accuracy: 0.4983 - val_loss: 1.2609 - val_accuracy: 0.5202\n",
      "Epoch 39/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.2699 - accuracy: 0.5054 - val_loss: 1.2374 - val_accuracy: 0.5239\n",
      "Epoch 40/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.2484 - accuracy: 0.5079 - val_loss: 1.2209 - val_accuracy: 0.5263\n",
      "Epoch 41/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.2307 - accuracy: 0.5154 - val_loss: 1.2001 - val_accuracy: 0.5318\n",
      "Epoch 42/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.2141 - accuracy: 0.5163 - val_loss: 1.1869 - val_accuracy: 0.5321\n",
      "Epoch 43/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.2008 - accuracy: 0.5201 - val_loss: 1.1739 - val_accuracy: 0.5320\n",
      "Epoch 44/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 1.1890 - accuracy: 0.5206 - val_loss: 1.1618 - val_accuracy: 0.5352\n",
      "Epoch 45/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.1787 - accuracy: 0.5213 - val_loss: 1.1542 - val_accuracy: 0.5434\n",
      "Epoch 46/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.1707 - accuracy: 0.5238 - val_loss: 1.1439 - val_accuracy: 0.5418\n",
      "Epoch 47/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.1621 - accuracy: 0.5238 - val_loss: 1.1366 - val_accuracy: 0.5396\n",
      "Epoch 48/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.1558 - accuracy: 0.5258 - val_loss: 1.1299 - val_accuracy: 0.5434\n",
      "Epoch 49/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.1494 - accuracy: 0.5279 - val_loss: 1.1253 - val_accuracy: 0.5441\n",
      "Epoch 50/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.1444 - accuracy: 0.5282 - val_loss: 1.1203 - val_accuracy: 0.5454\n",
      "Epoch 51/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.1399 - accuracy: 0.5281 - val_loss: 1.1146 - val_accuracy: 0.5441\n",
      "Epoch 52/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.1359 - accuracy: 0.5286 - val_loss: 1.1141 - val_accuracy: 0.5391\n",
      "Epoch 53/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.1320 - accuracy: 0.5297 - val_loss: 1.1062 - val_accuracy: 0.5445\n",
      "Epoch 54/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.1273 - accuracy: 0.5305 - val_loss: 1.1035 - val_accuracy: 0.5457\n",
      "Epoch 55/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.1242 - accuracy: 0.5296 - val_loss: 1.1009 - val_accuracy: 0.5455\n",
      "Epoch 56/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.1216 - accuracy: 0.5316 - val_loss: 1.0965 - val_accuracy: 0.5439\n",
      "Epoch 57/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.1195 - accuracy: 0.5308 - val_loss: 1.0946 - val_accuracy: 0.5461\n",
      "Epoch 58/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.1156 - accuracy: 0.5318 - val_loss: 1.0912 - val_accuracy: 0.5445\n",
      "Epoch 59/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.1130 - accuracy: 0.5314 - val_loss: 1.0889 - val_accuracy: 0.5443\n",
      "Epoch 60/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.1118 - accuracy: 0.5312 - val_loss: 1.0863 - val_accuracy: 0.5448\n",
      "Epoch 61/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.1083 - accuracy: 0.5340 - val_loss: 1.0866 - val_accuracy: 0.5457\n",
      "Epoch 62/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.1069 - accuracy: 0.5327 - val_loss: 1.0819 - val_accuracy: 0.5468\n",
      "Epoch 63/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.1047 - accuracy: 0.5339 - val_loss: 1.0808 - val_accuracy: 0.5443\n",
      "Epoch 64/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.1034 - accuracy: 0.5321 - val_loss: 1.0789 - val_accuracy: 0.5473\n",
      "Epoch 65/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.1008 - accuracy: 0.5336 - val_loss: 1.0763 - val_accuracy: 0.5482\n",
      "Epoch 66/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 1.0990 - accuracy: 0.5346 - val_loss: 1.0759 - val_accuracy: 0.5454\n",
      "Epoch 67/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.0967 - accuracy: 0.5358 - val_loss: 1.0725 - val_accuracy: 0.5525\n",
      "Epoch 68/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.0950 - accuracy: 0.5381 - val_loss: 1.0715 - val_accuracy: 0.5514\n",
      "Epoch 69/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.0929 - accuracy: 0.5361 - val_loss: 1.0723 - val_accuracy: 0.5448\n",
      "Epoch 70/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.0926 - accuracy: 0.5379 - val_loss: 1.0678 - val_accuracy: 0.5516\n",
      "Epoch 71/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.0893 - accuracy: 0.5387 - val_loss: 1.0643 - val_accuracy: 0.5502\n",
      "Epoch 72/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.0878 - accuracy: 0.5380 - val_loss: 1.0638 - val_accuracy: 0.5568\n",
      "Epoch 73/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.0849 - accuracy: 0.5381 - val_loss: 1.0592 - val_accuracy: 0.5534\n",
      "Epoch 74/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.0821 - accuracy: 0.5400 - val_loss: 1.0577 - val_accuracy: 0.5516\n",
      "Epoch 75/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.0812 - accuracy: 0.5396 - val_loss: 1.0547 - val_accuracy: 0.5536\n",
      "Epoch 76/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.0779 - accuracy: 0.5386 - val_loss: 1.0525 - val_accuracy: 0.5568\n",
      "Epoch 77/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.0750 - accuracy: 0.5406 - val_loss: 1.0509 - val_accuracy: 0.5562\n",
      "Epoch 78/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.0726 - accuracy: 0.5395 - val_loss: 1.0491 - val_accuracy: 0.5537\n",
      "Epoch 79/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.0716 - accuracy: 0.5411 - val_loss: 1.0473 - val_accuracy: 0.5566\n",
      "Epoch 80/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.0709 - accuracy: 0.5391 - val_loss: 1.0471 - val_accuracy: 0.5523\n",
      "Epoch 81/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.0669 - accuracy: 0.5423 - val_loss: 1.0437 - val_accuracy: 0.5559\n",
      "Epoch 82/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.0653 - accuracy: 0.5416 - val_loss: 1.0428 - val_accuracy: 0.5591\n",
      "Epoch 83/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.0637 - accuracy: 0.5422 - val_loss: 1.0405 - val_accuracy: 0.5580\n",
      "Epoch 84/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.0617 - accuracy: 0.5434 - val_loss: 1.0393 - val_accuracy: 0.5559\n",
      "Epoch 85/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.0613 - accuracy: 0.5442 - val_loss: 1.0387 - val_accuracy: 0.5561\n",
      "Epoch 86/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.0588 - accuracy: 0.5441 - val_loss: 1.0368 - val_accuracy: 0.5584\n",
      "Epoch 87/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.0574 - accuracy: 0.5441 - val_loss: 1.0351 - val_accuracy: 0.5595\n",
      "Epoch 88/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.0564 - accuracy: 0.5454 - val_loss: 1.0350 - val_accuracy: 0.5571\n",
      "Epoch 89/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.0545 - accuracy: 0.5464 - val_loss: 1.0329 - val_accuracy: 0.5598\n",
      "Epoch 90/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.0534 - accuracy: 0.5479 - val_loss: 1.0324 - val_accuracy: 0.5627\n",
      "Epoch 91/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.0523 - accuracy: 0.5461 - val_loss: 1.0300 - val_accuracy: 0.5614\n",
      "Epoch 92/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.0498 - accuracy: 0.5479 - val_loss: 1.0296 - val_accuracy: 0.5625\n",
      "Epoch 93/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.0493 - accuracy: 0.5485 - val_loss: 1.0286 - val_accuracy: 0.5638\n",
      "Epoch 94/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.0496 - accuracy: 0.5486 - val_loss: 1.0317 - val_accuracy: 0.5589\n",
      "Epoch 95/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.0468 - accuracy: 0.5499 - val_loss: 1.0253 - val_accuracy: 0.5648\n",
      "Epoch 96/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.0454 - accuracy: 0.5501 - val_loss: 1.0264 - val_accuracy: 0.5652\n",
      "Epoch 97/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.0456 - accuracy: 0.5490 - val_loss: 1.0252 - val_accuracy: 0.5641\n",
      "Epoch 98/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.0434 - accuracy: 0.5503 - val_loss: 1.0227 - val_accuracy: 0.5645\n",
      "Epoch 99/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.0427 - accuracy: 0.5507 - val_loss: 1.0234 - val_accuracy: 0.5629\n",
      "Epoch 100/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.0428 - accuracy: 0.5488 - val_loss: 1.0238 - val_accuracy: 0.5639\n",
      "Epoch 101/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.0426 - accuracy: 0.5490 - val_loss: 1.0215 - val_accuracy: 0.5679\n",
      "Epoch 102/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.0402 - accuracy: 0.5521 - val_loss: 1.0217 - val_accuracy: 0.5696\n",
      "Epoch 103/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 1.0389 - accuracy: 0.5509 - val_loss: 1.0191 - val_accuracy: 0.5700\n",
      "Epoch 104/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.0415 - accuracy: 0.5501 - val_loss: 1.0179 - val_accuracy: 0.5655\n",
      "Epoch 105/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.0407 - accuracy: 0.5527 - val_loss: 1.0193 - val_accuracy: 0.5693\n",
      "Epoch 106/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.0369 - accuracy: 0.5517 - val_loss: 1.0188 - val_accuracy: 0.5682\n",
      "Epoch 107/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.0358 - accuracy: 0.5518 - val_loss: 1.0192 - val_accuracy: 0.5664\n",
      "Epoch 108/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.0349 - accuracy: 0.5537 - val_loss: 1.0142 - val_accuracy: 0.5696\n",
      "Epoch 109/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.0340 - accuracy: 0.5542 - val_loss: 1.0150 - val_accuracy: 0.5707\n",
      "Epoch 110/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.0334 - accuracy: 0.5543 - val_loss: 1.0151 - val_accuracy: 0.5684\n",
      "Epoch 111/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.0324 - accuracy: 0.5554 - val_loss: 1.0128 - val_accuracy: 0.5707\n",
      "Epoch 112/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.0328 - accuracy: 0.5544 - val_loss: 1.0123 - val_accuracy: 0.5689\n",
      "Epoch 113/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.0319 - accuracy: 0.5565 - val_loss: 1.0116 - val_accuracy: 0.5732\n",
      "Epoch 114/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.0306 - accuracy: 0.5554 - val_loss: 1.0109 - val_accuracy: 0.5752\n",
      "Epoch 115/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.0303 - accuracy: 0.5558 - val_loss: 1.0100 - val_accuracy: 0.5757\n",
      "Epoch 116/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.0291 - accuracy: 0.5565 - val_loss: 1.0142 - val_accuracy: 0.5675\n",
      "Epoch 117/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.0292 - accuracy: 0.5564 - val_loss: 1.0087 - val_accuracy: 0.5752\n",
      "Epoch 118/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.0269 - accuracy: 0.5587 - val_loss: 1.0074 - val_accuracy: 0.5761\n",
      "Epoch 119/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.0262 - accuracy: 0.5576 - val_loss: 1.0083 - val_accuracy: 0.5741\n",
      "Epoch 120/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.0258 - accuracy: 0.5589 - val_loss: 1.0078 - val_accuracy: 0.5748\n",
      "Epoch 121/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.0246 - accuracy: 0.5593 - val_loss: 1.0062 - val_accuracy: 0.5748\n",
      "Epoch 122/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.0243 - accuracy: 0.5597 - val_loss: 1.0040 - val_accuracy: 0.5718\n",
      "Epoch 123/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.0232 - accuracy: 0.5587 - val_loss: 1.0027 - val_accuracy: 0.5752\n",
      "Epoch 124/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.0233 - accuracy: 0.5597 - val_loss: 1.0017 - val_accuracy: 0.5779\n",
      "Epoch 125/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.0212 - accuracy: 0.5608 - val_loss: 1.0022 - val_accuracy: 0.5750\n",
      "Epoch 126/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.0216 - accuracy: 0.5604 - val_loss: 1.0004 - val_accuracy: 0.5746\n",
      "Epoch 127/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.0205 - accuracy: 0.5582 - val_loss: 1.0024 - val_accuracy: 0.5766\n",
      "Epoch 128/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.0195 - accuracy: 0.5629 - val_loss: 0.9984 - val_accuracy: 0.5771\n",
      "Epoch 129/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.0183 - accuracy: 0.5624 - val_loss: 0.9982 - val_accuracy: 0.5814\n",
      "Epoch 130/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.0171 - accuracy: 0.5625 - val_loss: 0.9980 - val_accuracy: 0.5768\n",
      "Epoch 131/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.0172 - accuracy: 0.5632 - val_loss: 0.9961 - val_accuracy: 0.5802\n",
      "Epoch 132/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.0156 - accuracy: 0.5629 - val_loss: 0.9952 - val_accuracy: 0.5786\n",
      "Epoch 133/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.0146 - accuracy: 0.5636 - val_loss: 0.9943 - val_accuracy: 0.5805\n",
      "Epoch 134/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.0154 - accuracy: 0.5653 - val_loss: 0.9970 - val_accuracy: 0.5795\n",
      "Epoch 135/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.0133 - accuracy: 0.5646 - val_loss: 0.9935 - val_accuracy: 0.5800\n",
      "Epoch 136/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.0122 - accuracy: 0.5667 - val_loss: 0.9920 - val_accuracy: 0.5807\n",
      "Epoch 137/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.0113 - accuracy: 0.5656 - val_loss: 0.9934 - val_accuracy: 0.5809\n",
      "Epoch 138/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.0104 - accuracy: 0.5672 - val_loss: 0.9898 - val_accuracy: 0.5841\n",
      "Epoch 139/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 1.0097 - accuracy: 0.5671 - val_loss: 0.9892 - val_accuracy: 0.5823\n",
      "Epoch 140/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.0088 - accuracy: 0.5670 - val_loss: 0.9940 - val_accuracy: 0.5816\n",
      "Epoch 141/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.0106 - accuracy: 0.5643 - val_loss: 0.9875 - val_accuracy: 0.5829\n",
      "Epoch 142/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.0072 - accuracy: 0.5688 - val_loss: 0.9870 - val_accuracy: 0.5852\n",
      "Epoch 143/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.0062 - accuracy: 0.5677 - val_loss: 0.9850 - val_accuracy: 0.5863\n",
      "Epoch 144/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.0046 - accuracy: 0.5703 - val_loss: 0.9850 - val_accuracy: 0.5879\n",
      "Epoch 145/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.0035 - accuracy: 0.5698 - val_loss: 0.9840 - val_accuracy: 0.5873\n",
      "Epoch 146/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.0031 - accuracy: 0.5697 - val_loss: 0.9820 - val_accuracy: 0.5884\n",
      "Epoch 147/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.0017 - accuracy: 0.5710 - val_loss: 0.9818 - val_accuracy: 0.5882\n",
      "Epoch 148/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.0008 - accuracy: 0.5732 - val_loss: 0.9804 - val_accuracy: 0.5911\n",
      "Epoch 149/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.9992 - accuracy: 0.5739 - val_loss: 0.9791 - val_accuracy: 0.5913\n",
      "Epoch 150/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.9978 - accuracy: 0.5750 - val_loss: 0.9785 - val_accuracy: 0.5886\n",
      "Epoch 151/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.9970 - accuracy: 0.5744 - val_loss: 0.9772 - val_accuracy: 0.5936\n",
      "Epoch 152/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.9953 - accuracy: 0.5768 - val_loss: 0.9752 - val_accuracy: 0.5934\n",
      "Epoch 153/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.9944 - accuracy: 0.5762 - val_loss: 0.9751 - val_accuracy: 0.5943\n",
      "Epoch 154/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.9935 - accuracy: 0.5776 - val_loss: 0.9718 - val_accuracy: 0.5941\n",
      "Epoch 155/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.9913 - accuracy: 0.5784 - val_loss: 0.9704 - val_accuracy: 0.5957\n",
      "Epoch 156/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.9903 - accuracy: 0.5780 - val_loss: 0.9688 - val_accuracy: 0.5970\n",
      "Epoch 157/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.9879 - accuracy: 0.5795 - val_loss: 0.9683 - val_accuracy: 0.5975\n",
      "Epoch 158/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.9896 - accuracy: 0.5796 - val_loss: 0.9665 - val_accuracy: 0.5975\n",
      "Epoch 159/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.9840 - accuracy: 0.5826 - val_loss: 0.9637 - val_accuracy: 0.5995\n",
      "Epoch 160/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.9818 - accuracy: 0.5839 - val_loss: 0.9619 - val_accuracy: 0.6009\n",
      "Epoch 161/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.9798 - accuracy: 0.5826 - val_loss: 0.9604 - val_accuracy: 0.6000\n",
      "Epoch 162/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.9776 - accuracy: 0.5857 - val_loss: 0.9581 - val_accuracy: 0.6050\n",
      "Epoch 163/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.9754 - accuracy: 0.5862 - val_loss: 0.9552 - val_accuracy: 0.6027\n",
      "Epoch 164/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.9736 - accuracy: 0.5887 - val_loss: 0.9535 - val_accuracy: 0.6061\n",
      "Epoch 165/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.9699 - accuracy: 0.5914 - val_loss: 0.9501 - val_accuracy: 0.6073\n",
      "Epoch 166/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.9673 - accuracy: 0.5916 - val_loss: 0.9483 - val_accuracy: 0.6073\n",
      "Epoch 167/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.9657 - accuracy: 0.5916 - val_loss: 0.9465 - val_accuracy: 0.6098\n",
      "Epoch 168/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.9621 - accuracy: 0.5951 - val_loss: 0.9424 - val_accuracy: 0.6079\n",
      "Epoch 169/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.9593 - accuracy: 0.5979 - val_loss: 0.9392 - val_accuracy: 0.6173\n",
      "Epoch 170/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.9562 - accuracy: 0.5979 - val_loss: 0.9353 - val_accuracy: 0.6162\n",
      "Epoch 171/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.9529 - accuracy: 0.6004 - val_loss: 0.9326 - val_accuracy: 0.6171\n",
      "Epoch 172/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.9484 - accuracy: 0.6033 - val_loss: 0.9307 - val_accuracy: 0.6189\n",
      "Epoch 173/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.9436 - accuracy: 0.6064 - val_loss: 0.9247 - val_accuracy: 0.6212\n",
      "Epoch 174/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.9406 - accuracy: 0.6079 - val_loss: 0.9223 - val_accuracy: 0.6255\n",
      "Epoch 175/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.9364 - accuracy: 0.6112 - val_loss: 0.9171 - val_accuracy: 0.6284\n",
      "Epoch 176/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.9318 - accuracy: 0.6127 - val_loss: 0.9118 - val_accuracy: 0.6302\n",
      "Epoch 177/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.9275 - accuracy: 0.6163 - val_loss: 0.9087 - val_accuracy: 0.6311\n",
      "Epoch 178/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.9218 - accuracy: 0.6192 - val_loss: 0.9031 - val_accuracy: 0.6375\n",
      "Epoch 179/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.9176 - accuracy: 0.6246 - val_loss: 0.9016 - val_accuracy: 0.6391\n",
      "Epoch 180/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.9121 - accuracy: 0.6268 - val_loss: 0.8923 - val_accuracy: 0.6425\n",
      "Epoch 181/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.9063 - accuracy: 0.6303 - val_loss: 0.8923 - val_accuracy: 0.6473\n",
      "Epoch 182/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.9004 - accuracy: 0.6329 - val_loss: 0.8814 - val_accuracy: 0.6489\n",
      "Epoch 183/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.8934 - accuracy: 0.6385 - val_loss: 0.8772 - val_accuracy: 0.6507\n",
      "Epoch 184/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.8877 - accuracy: 0.6409 - val_loss: 0.8692 - val_accuracy: 0.6561\n",
      "Epoch 185/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.8825 - accuracy: 0.6453 - val_loss: 0.8656 - val_accuracy: 0.6568\n",
      "Epoch 186/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8745 - accuracy: 0.6513 - val_loss: 0.8580 - val_accuracy: 0.6641\n",
      "Epoch 187/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.8676 - accuracy: 0.6520 - val_loss: 0.8491 - val_accuracy: 0.6645\n",
      "Epoch 188/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.8609 - accuracy: 0.6574 - val_loss: 0.8430 - val_accuracy: 0.6661\n",
      "Epoch 189/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.8529 - accuracy: 0.6628 - val_loss: 0.8359 - val_accuracy: 0.6734\n",
      "Epoch 190/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.8461 - accuracy: 0.6655 - val_loss: 0.8343 - val_accuracy: 0.6664\n",
      "Epoch 191/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.8433 - accuracy: 0.6667 - val_loss: 0.8262 - val_accuracy: 0.6725\n",
      "Epoch 192/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.8327 - accuracy: 0.6737 - val_loss: 0.8207 - val_accuracy: 0.6775\n",
      "Epoch 193/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.8284 - accuracy: 0.6743 - val_loss: 0.8120 - val_accuracy: 0.6841\n",
      "Epoch 194/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.8226 - accuracy: 0.6772 - val_loss: 0.8104 - val_accuracy: 0.6779\n",
      "Epoch 195/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.8156 - accuracy: 0.6808 - val_loss: 0.8029 - val_accuracy: 0.6811\n",
      "Epoch 196/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.8087 - accuracy: 0.6817 - val_loss: 0.7950 - val_accuracy: 0.6943\n",
      "Epoch 197/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.8037 - accuracy: 0.6865 - val_loss: 0.7914 - val_accuracy: 0.6973\n",
      "Epoch 198/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7978 - accuracy: 0.6881 - val_loss: 0.7838 - val_accuracy: 0.6968\n",
      "Epoch 199/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7935 - accuracy: 0.6886 - val_loss: 0.7786 - val_accuracy: 0.6996\n",
      "Epoch 200/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7886 - accuracy: 0.6913 - val_loss: 0.7752 - val_accuracy: 0.7004\n",
      "Epoch 201/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7843 - accuracy: 0.6923 - val_loss: 0.7705 - val_accuracy: 0.6984\n",
      "Epoch 202/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7804 - accuracy: 0.6930 - val_loss: 0.7683 - val_accuracy: 0.6998\n",
      "Epoch 203/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7775 - accuracy: 0.6937 - val_loss: 0.7629 - val_accuracy: 0.7046\n",
      "Epoch 204/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7739 - accuracy: 0.6958 - val_loss: 0.7590 - val_accuracy: 0.7018\n",
      "Epoch 205/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7679 - accuracy: 0.6950 - val_loss: 0.7554 - val_accuracy: 0.7021\n",
      "Epoch 206/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7651 - accuracy: 0.6970 - val_loss: 0.7545 - val_accuracy: 0.6995\n",
      "Epoch 207/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7616 - accuracy: 0.6974 - val_loss: 0.7509 - val_accuracy: 0.7102\n",
      "Epoch 208/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7607 - accuracy: 0.6979 - val_loss: 0.7582 - val_accuracy: 0.7050\n",
      "Epoch 209/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7559 - accuracy: 0.6985 - val_loss: 0.7440 - val_accuracy: 0.7045\n",
      "Epoch 210/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7529 - accuracy: 0.7011 - val_loss: 0.7418 - val_accuracy: 0.7032\n",
      "Epoch 211/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7503 - accuracy: 0.7016 - val_loss: 0.7388 - val_accuracy: 0.7046\n",
      "Epoch 212/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7480 - accuracy: 0.7011 - val_loss: 0.7372 - val_accuracy: 0.7091\n",
      "Epoch 213/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7472 - accuracy: 0.7013 - val_loss: 0.7353 - val_accuracy: 0.7091\n",
      "Epoch 214/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7430 - accuracy: 0.7036 - val_loss: 0.7320 - val_accuracy: 0.7054\n",
      "Epoch 215/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7415 - accuracy: 0.7040 - val_loss: 0.7339 - val_accuracy: 0.7088\n",
      "Epoch 216/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7406 - accuracy: 0.7047 - val_loss: 0.7328 - val_accuracy: 0.7091\n",
      "Epoch 217/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7375 - accuracy: 0.7047 - val_loss: 0.7268 - val_accuracy: 0.7098\n",
      "Epoch 218/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7356 - accuracy: 0.7042 - val_loss: 0.7278 - val_accuracy: 0.7082\n",
      "Epoch 219/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7331 - accuracy: 0.7058 - val_loss: 0.7240 - val_accuracy: 0.7091\n",
      "Epoch 220/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7328 - accuracy: 0.7055 - val_loss: 0.7248 - val_accuracy: 0.7121\n",
      "Epoch 221/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7294 - accuracy: 0.7060 - val_loss: 0.7200 - val_accuracy: 0.7121\n",
      "Epoch 222/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7288 - accuracy: 0.7086 - val_loss: 0.7234 - val_accuracy: 0.7141\n",
      "Epoch 223/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7259 - accuracy: 0.7076 - val_loss: 0.7180 - val_accuracy: 0.7134\n",
      "Epoch 224/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7246 - accuracy: 0.7096 - val_loss: 0.7161 - val_accuracy: 0.7104\n",
      "Epoch 225/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7230 - accuracy: 0.7092 - val_loss: 0.7156 - val_accuracy: 0.7113\n",
      "Epoch 226/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7219 - accuracy: 0.7088 - val_loss: 0.7133 - val_accuracy: 0.7114\n",
      "Epoch 227/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7205 - accuracy: 0.7092 - val_loss: 0.7128 - val_accuracy: 0.7093\n",
      "Epoch 228/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7206 - accuracy: 0.7103 - val_loss: 0.7127 - val_accuracy: 0.7116\n",
      "Epoch 229/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7184 - accuracy: 0.7093 - val_loss: 0.7107 - val_accuracy: 0.7152\n",
      "Epoch 230/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7193 - accuracy: 0.7138 - val_loss: 0.7097 - val_accuracy: 0.7084\n",
      "Epoch 231/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7194 - accuracy: 0.7091 - val_loss: 0.7125 - val_accuracy: 0.7132\n",
      "Epoch 232/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7172 - accuracy: 0.7106 - val_loss: 0.7076 - val_accuracy: 0.7139\n",
      "Epoch 233/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7154 - accuracy: 0.7131 - val_loss: 0.7074 - val_accuracy: 0.7104\n",
      "Epoch 234/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7147 - accuracy: 0.7110 - val_loss: 0.7055 - val_accuracy: 0.7130\n",
      "Epoch 235/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7136 - accuracy: 0.7109 - val_loss: 0.7044 - val_accuracy: 0.7129\n",
      "Epoch 236/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7142 - accuracy: 0.7136 - val_loss: 0.7075 - val_accuracy: 0.7143\n",
      "Epoch 237/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7116 - accuracy: 0.7116 - val_loss: 0.7032 - val_accuracy: 0.7150\n",
      "Epoch 238/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7112 - accuracy: 0.7123 - val_loss: 0.7022 - val_accuracy: 0.7141\n",
      "Epoch 239/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7110 - accuracy: 0.7117 - val_loss: 0.7025 - val_accuracy: 0.7148\n",
      "Epoch 240/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7090 - accuracy: 0.7129 - val_loss: 0.7011 - val_accuracy: 0.7164\n",
      "Epoch 241/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7079 - accuracy: 0.7131 - val_loss: 0.7016 - val_accuracy: 0.7139\n",
      "Epoch 242/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7073 - accuracy: 0.7140 - val_loss: 0.6997 - val_accuracy: 0.7152\n",
      "Epoch 243/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7077 - accuracy: 0.7131 - val_loss: 0.7012 - val_accuracy: 0.7166\n",
      "Epoch 244/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7067 - accuracy: 0.7127 - val_loss: 0.6991 - val_accuracy: 0.7154\n",
      "Epoch 245/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7076 - accuracy: 0.7129 - val_loss: 0.7054 - val_accuracy: 0.7150\n",
      "Epoch 246/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7059 - accuracy: 0.7137 - val_loss: 0.6996 - val_accuracy: 0.7146\n",
      "Epoch 247/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7047 - accuracy: 0.7138 - val_loss: 0.6965 - val_accuracy: 0.7159\n",
      "Epoch 248/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7047 - accuracy: 0.7162 - val_loss: 0.6965 - val_accuracy: 0.7139\n",
      "Epoch 249/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7036 - accuracy: 0.7137 - val_loss: 0.6960 - val_accuracy: 0.7148\n",
      "Epoch 250/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7059 - accuracy: 0.7134 - val_loss: 0.7017 - val_accuracy: 0.7136\n",
      "Epoch 251/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7052 - accuracy: 0.7138 - val_loss: 0.7029 - val_accuracy: 0.7164\n",
      "Epoch 252/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7064 - accuracy: 0.7128 - val_loss: 0.6954 - val_accuracy: 0.7175\n",
      "Epoch 253/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7024 - accuracy: 0.7146 - val_loss: 0.6948 - val_accuracy: 0.7157\n",
      "Epoch 254/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7029 - accuracy: 0.7148 - val_loss: 0.6935 - val_accuracy: 0.7159\n",
      "Epoch 255/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7013 - accuracy: 0.7162 - val_loss: 0.6935 - val_accuracy: 0.7166\n",
      "Epoch 256/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7019 - accuracy: 0.7155 - val_loss: 0.6925 - val_accuracy: 0.7163\n",
      "Epoch 257/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7005 - accuracy: 0.7146 - val_loss: 0.6952 - val_accuracy: 0.7157\n",
      "Epoch 258/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7029 - accuracy: 0.7162 - val_loss: 0.6938 - val_accuracy: 0.7173\n",
      "Epoch 259/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6993 - accuracy: 0.7161 - val_loss: 0.6919 - val_accuracy: 0.7145\n",
      "Epoch 260/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6983 - accuracy: 0.7179 - val_loss: 0.6907 - val_accuracy: 0.7173\n",
      "Epoch 261/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6995 - accuracy: 0.7179 - val_loss: 0.6960 - val_accuracy: 0.7130\n",
      "Epoch 262/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6999 - accuracy: 0.7167 - val_loss: 0.6903 - val_accuracy: 0.7179\n",
      "Epoch 263/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6987 - accuracy: 0.7173 - val_loss: 0.6895 - val_accuracy: 0.7168\n",
      "Epoch 264/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6981 - accuracy: 0.7163 - val_loss: 0.6900 - val_accuracy: 0.7184\n",
      "Epoch 265/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6965 - accuracy: 0.7174 - val_loss: 0.6909 - val_accuracy: 0.7184\n",
      "Epoch 266/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6961 - accuracy: 0.7164 - val_loss: 0.6899 - val_accuracy: 0.7196\n",
      "Epoch 267/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6983 - accuracy: 0.7153 - val_loss: 0.6922 - val_accuracy: 0.7193\n",
      "Epoch 268/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6975 - accuracy: 0.7163 - val_loss: 0.6888 - val_accuracy: 0.7175\n",
      "Epoch 269/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6953 - accuracy: 0.7188 - val_loss: 0.6904 - val_accuracy: 0.7195\n",
      "Epoch 270/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6964 - accuracy: 0.7175 - val_loss: 0.6877 - val_accuracy: 0.7179\n",
      "Epoch 271/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6964 - accuracy: 0.7180 - val_loss: 0.6946 - val_accuracy: 0.7170\n",
      "Epoch 272/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6970 - accuracy: 0.7157 - val_loss: 0.6881 - val_accuracy: 0.7209\n",
      "Epoch 273/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6952 - accuracy: 0.7179 - val_loss: 0.6867 - val_accuracy: 0.7182\n",
      "Epoch 274/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6942 - accuracy: 0.7193 - val_loss: 0.6876 - val_accuracy: 0.7175\n",
      "Epoch 275/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6938 - accuracy: 0.7189 - val_loss: 0.6866 - val_accuracy: 0.7154\n",
      "Epoch 276/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6957 - accuracy: 0.7169 - val_loss: 0.6882 - val_accuracy: 0.7188\n",
      "Epoch 277/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6936 - accuracy: 0.7180 - val_loss: 0.6882 - val_accuracy: 0.7179\n",
      "Epoch 278/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6944 - accuracy: 0.7192 - val_loss: 0.6863 - val_accuracy: 0.7155\n",
      "Epoch 279/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6933 - accuracy: 0.7191 - val_loss: 0.6843 - val_accuracy: 0.7191\n",
      "Epoch 280/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6946 - accuracy: 0.7174 - val_loss: 0.6851 - val_accuracy: 0.7193\n",
      "Epoch 281/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6927 - accuracy: 0.7196 - val_loss: 0.6840 - val_accuracy: 0.7196\n",
      "Epoch 282/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6949 - accuracy: 0.7177 - val_loss: 0.6902 - val_accuracy: 0.7154\n",
      "Epoch 283/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6946 - accuracy: 0.7179 - val_loss: 0.6863 - val_accuracy: 0.7150\n",
      "Epoch 284/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6939 - accuracy: 0.7192 - val_loss: 0.6851 - val_accuracy: 0.7179\n",
      "Epoch 285/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.7191 - val_loss: 0.6830 - val_accuracy: 0.7171\n",
      "Epoch 286/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6909 - accuracy: 0.7191 - val_loss: 0.6833 - val_accuracy: 0.7200\n",
      "Epoch 287/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6910 - accuracy: 0.7210 - val_loss: 0.6863 - val_accuracy: 0.7184\n",
      "Epoch 288/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6921 - accuracy: 0.7200 - val_loss: 0.6843 - val_accuracy: 0.7214\n",
      "Epoch 289/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6906 - accuracy: 0.7186 - val_loss: 0.6817 - val_accuracy: 0.7212\n",
      "Epoch 290/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6898 - accuracy: 0.7209 - val_loss: 0.6840 - val_accuracy: 0.7204\n",
      "Epoch 291/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6906 - accuracy: 0.7197 - val_loss: 0.6856 - val_accuracy: 0.7207\n",
      "Epoch 292/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6916 - accuracy: 0.7163 - val_loss: 0.6852 - val_accuracy: 0.7223\n",
      "Epoch 293/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6902 - accuracy: 0.7205 - val_loss: 0.6874 - val_accuracy: 0.7184\n",
      "Epoch 294/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6918 - accuracy: 0.7192 - val_loss: 0.6857 - val_accuracy: 0.7207\n",
      "Epoch 295/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6941 - accuracy: 0.7161 - val_loss: 0.6814 - val_accuracy: 0.7188\n",
      "Epoch 296/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6896 - accuracy: 0.7196 - val_loss: 0.6803 - val_accuracy: 0.7221\n",
      "Epoch 297/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6891 - accuracy: 0.7196 - val_loss: 0.6825 - val_accuracy: 0.7212\n",
      "Epoch 298/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6901 - accuracy: 0.7201 - val_loss: 0.6824 - val_accuracy: 0.7184\n",
      "Epoch 299/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6897 - accuracy: 0.7188 - val_loss: 0.6808 - val_accuracy: 0.7166\n",
      "Epoch 300/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6898 - accuracy: 0.7195 - val_loss: 0.6791 - val_accuracy: 0.7196\n",
      "Epoch 301/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6883 - accuracy: 0.7201 - val_loss: 0.6798 - val_accuracy: 0.7218\n",
      "Epoch 302/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6885 - accuracy: 0.7217 - val_loss: 0.6806 - val_accuracy: 0.7179\n",
      "Epoch 303/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6881 - accuracy: 0.7219 - val_loss: 0.6791 - val_accuracy: 0.7227\n",
      "Epoch 304/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6882 - accuracy: 0.7200 - val_loss: 0.6803 - val_accuracy: 0.7168\n",
      "Epoch 305/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6882 - accuracy: 0.7208 - val_loss: 0.6798 - val_accuracy: 0.7216\n",
      "Epoch 306/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6895 - accuracy: 0.7193 - val_loss: 0.6844 - val_accuracy: 0.7223\n",
      "Epoch 307/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6886 - accuracy: 0.7204 - val_loss: 0.6791 - val_accuracy: 0.7202\n",
      "Epoch 308/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6866 - accuracy: 0.7215 - val_loss: 0.6787 - val_accuracy: 0.7198\n",
      "Epoch 309/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6873 - accuracy: 0.7199 - val_loss: 0.6779 - val_accuracy: 0.7214\n",
      "Epoch 310/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6869 - accuracy: 0.7211 - val_loss: 0.6777 - val_accuracy: 0.7214\n",
      "Epoch 311/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6879 - accuracy: 0.7204 - val_loss: 0.6776 - val_accuracy: 0.7230\n",
      "Epoch 312/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6863 - accuracy: 0.7197 - val_loss: 0.6787 - val_accuracy: 0.7175\n",
      "Epoch 313/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6866 - accuracy: 0.7215 - val_loss: 0.6785 - val_accuracy: 0.7211\n",
      "Epoch 314/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6875 - accuracy: 0.7211 - val_loss: 0.6803 - val_accuracy: 0.7218\n",
      "Epoch 315/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6855 - accuracy: 0.7219 - val_loss: 0.6816 - val_accuracy: 0.7241\n",
      "Epoch 316/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6875 - accuracy: 0.7194 - val_loss: 0.6819 - val_accuracy: 0.7177\n",
      "Epoch 317/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6860 - accuracy: 0.7204 - val_loss: 0.6760 - val_accuracy: 0.7241\n",
      "Epoch 318/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6862 - accuracy: 0.7206 - val_loss: 0.6764 - val_accuracy: 0.7211\n",
      "Epoch 319/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6852 - accuracy: 0.7221 - val_loss: 0.6759 - val_accuracy: 0.7232\n",
      "Epoch 320/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6859 - accuracy: 0.7218 - val_loss: 0.6760 - val_accuracy: 0.7204\n",
      "Epoch 321/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6845 - accuracy: 0.7215 - val_loss: 0.6776 - val_accuracy: 0.7218\n",
      "Epoch 322/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6844 - accuracy: 0.7202 - val_loss: 0.6771 - val_accuracy: 0.7239\n",
      "Epoch 323/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6851 - accuracy: 0.7221 - val_loss: 0.6784 - val_accuracy: 0.7202\n",
      "Epoch 324/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6850 - accuracy: 0.7210 - val_loss: 0.6781 - val_accuracy: 0.7254\n",
      "Epoch 325/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6844 - accuracy: 0.7221 - val_loss: 0.6746 - val_accuracy: 0.7239\n",
      "Epoch 326/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6833 - accuracy: 0.7224 - val_loss: 0.6759 - val_accuracy: 0.7230\n",
      "Epoch 327/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6849 - accuracy: 0.7216 - val_loss: 0.6777 - val_accuracy: 0.7205\n",
      "Epoch 328/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6848 - accuracy: 0.7209 - val_loss: 0.6791 - val_accuracy: 0.7237\n",
      "Epoch 329/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6857 - accuracy: 0.7221 - val_loss: 0.6746 - val_accuracy: 0.7229\n",
      "Epoch 330/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6863 - accuracy: 0.7212 - val_loss: 0.6765 - val_accuracy: 0.7205\n",
      "Epoch 331/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6828 - accuracy: 0.7219 - val_loss: 0.6748 - val_accuracy: 0.7234\n",
      "Epoch 332/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6830 - accuracy: 0.7219 - val_loss: 0.6749 - val_accuracy: 0.7229\n",
      "Epoch 333/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6833 - accuracy: 0.7225 - val_loss: 0.6745 - val_accuracy: 0.7216\n",
      "Epoch 334/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6830 - accuracy: 0.7222 - val_loss: 0.6754 - val_accuracy: 0.7225\n",
      "Epoch 335/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6835 - accuracy: 0.7225 - val_loss: 0.6747 - val_accuracy: 0.7239\n",
      "Epoch 336/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6838 - accuracy: 0.7227 - val_loss: 0.6744 - val_accuracy: 0.7220\n",
      "Epoch 337/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6827 - accuracy: 0.7225 - val_loss: 0.6828 - val_accuracy: 0.7216\n",
      "Epoch 338/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6849 - accuracy: 0.7225 - val_loss: 0.6753 - val_accuracy: 0.7254\n",
      "Epoch 339/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6834 - accuracy: 0.7217 - val_loss: 0.6759 - val_accuracy: 0.7225\n",
      "Epoch 340/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6823 - accuracy: 0.7235 - val_loss: 0.6744 - val_accuracy: 0.7214\n",
      "Epoch 341/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6818 - accuracy: 0.7225 - val_loss: 0.6744 - val_accuracy: 0.7257\n",
      "Epoch 342/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6825 - accuracy: 0.7229 - val_loss: 0.6743 - val_accuracy: 0.7230\n",
      "Epoch 343/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6824 - accuracy: 0.7229 - val_loss: 0.6730 - val_accuracy: 0.7223\n",
      "Epoch 344/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6831 - accuracy: 0.7219 - val_loss: 0.6734 - val_accuracy: 0.7220\n",
      "Epoch 345/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6830 - accuracy: 0.7223 - val_loss: 0.6725 - val_accuracy: 0.7243\n",
      "Epoch 346/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6817 - accuracy: 0.7231 - val_loss: 0.6724 - val_accuracy: 0.7236\n",
      "Epoch 347/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6811 - accuracy: 0.7222 - val_loss: 0.6734 - val_accuracy: 0.7257\n",
      "Epoch 348/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6826 - accuracy: 0.7209 - val_loss: 0.6734 - val_accuracy: 0.7246\n",
      "Epoch 349/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6830 - accuracy: 0.7220 - val_loss: 0.6779 - val_accuracy: 0.7236\n",
      "Epoch 350/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6818 - accuracy: 0.7237 - val_loss: 0.6727 - val_accuracy: 0.7223\n",
      "Epoch 351/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6808 - accuracy: 0.7231 - val_loss: 0.6727 - val_accuracy: 0.7237\n",
      "Epoch 352/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6812 - accuracy: 0.7225 - val_loss: 0.6725 - val_accuracy: 0.7223\n",
      "Epoch 353/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6810 - accuracy: 0.7241 - val_loss: 0.6731 - val_accuracy: 0.7223\n",
      "Epoch 354/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6804 - accuracy: 0.7234 - val_loss: 0.6709 - val_accuracy: 0.7243\n",
      "Epoch 355/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6803 - accuracy: 0.7228 - val_loss: 0.6710 - val_accuracy: 0.7232\n",
      "Epoch 356/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6811 - accuracy: 0.7241 - val_loss: 0.6713 - val_accuracy: 0.7243\n",
      "Epoch 357/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6822 - accuracy: 0.7207 - val_loss: 0.6739 - val_accuracy: 0.7229\n",
      "Epoch 358/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6815 - accuracy: 0.7214 - val_loss: 0.6710 - val_accuracy: 0.7241\n",
      "Epoch 359/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6795 - accuracy: 0.7237 - val_loss: 0.6709 - val_accuracy: 0.7257\n",
      "Epoch 360/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6803 - accuracy: 0.7233 - val_loss: 0.6722 - val_accuracy: 0.7246\n",
      "Epoch 361/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6800 - accuracy: 0.7237 - val_loss: 0.6702 - val_accuracy: 0.7232\n",
      "Epoch 362/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6805 - accuracy: 0.7215 - val_loss: 0.6710 - val_accuracy: 0.7237\n",
      "Epoch 363/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6797 - accuracy: 0.7242 - val_loss: 0.6702 - val_accuracy: 0.7236\n",
      "Epoch 364/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6800 - accuracy: 0.7234 - val_loss: 0.6715 - val_accuracy: 0.7207\n",
      "Epoch 365/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6811 - accuracy: 0.7221 - val_loss: 0.6712 - val_accuracy: 0.7237\n",
      "Epoch 366/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6800 - accuracy: 0.7231 - val_loss: 0.6718 - val_accuracy: 0.7237\n",
      "Epoch 367/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6792 - accuracy: 0.7245 - val_loss: 0.6728 - val_accuracy: 0.7230\n",
      "Epoch 368/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6805 - accuracy: 0.7227 - val_loss: 0.6695 - val_accuracy: 0.7237\n",
      "Epoch 369/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6793 - accuracy: 0.7230 - val_loss: 0.6774 - val_accuracy: 0.7211\n",
      "Epoch 370/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6806 - accuracy: 0.7225 - val_loss: 0.6712 - val_accuracy: 0.7243\n",
      "Epoch 371/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6796 - accuracy: 0.7238 - val_loss: 0.6698 - val_accuracy: 0.7261\n",
      "Epoch 372/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6801 - accuracy: 0.7245 - val_loss: 0.6694 - val_accuracy: 0.7250\n",
      "Epoch 373/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6786 - accuracy: 0.7247 - val_loss: 0.6713 - val_accuracy: 0.7232\n",
      "Epoch 374/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6800 - accuracy: 0.7226 - val_loss: 0.6696 - val_accuracy: 0.7232\n",
      "Epoch 375/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6787 - accuracy: 0.7233 - val_loss: 0.6693 - val_accuracy: 0.7271\n",
      "Epoch 376/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6790 - accuracy: 0.7230 - val_loss: 0.6687 - val_accuracy: 0.7259\n",
      "Epoch 377/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6783 - accuracy: 0.7237 - val_loss: 0.6709 - val_accuracy: 0.7245\n",
      "Epoch 378/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6780 - accuracy: 0.7249 - val_loss: 0.6691 - val_accuracy: 0.7245\n",
      "Epoch 379/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6794 - accuracy: 0.7234 - val_loss: 0.6696 - val_accuracy: 0.7243\n",
      "Epoch 380/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6803 - accuracy: 0.7229 - val_loss: 0.6702 - val_accuracy: 0.7243\n",
      "Epoch 381/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6778 - accuracy: 0.7243 - val_loss: 0.6693 - val_accuracy: 0.7241\n",
      "Epoch 382/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6782 - accuracy: 0.7240 - val_loss: 0.6695 - val_accuracy: 0.7259\n",
      "Epoch 383/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6795 - accuracy: 0.7226 - val_loss: 0.6713 - val_accuracy: 0.7232\n",
      "Epoch 384/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6802 - accuracy: 0.7213 - val_loss: 0.6744 - val_accuracy: 0.7243\n",
      "Epoch 385/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6811 - accuracy: 0.7197 - val_loss: 0.6753 - val_accuracy: 0.7207\n",
      "Epoch 386/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6796 - accuracy: 0.7224 - val_loss: 0.6708 - val_accuracy: 0.7257\n",
      "Epoch 387/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6772 - accuracy: 0.7245 - val_loss: 0.6692 - val_accuracy: 0.7250\n",
      "Epoch 388/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6794 - accuracy: 0.7247 - val_loss: 0.6699 - val_accuracy: 0.7273\n",
      "Epoch 389/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6813 - accuracy: 0.7231 - val_loss: 0.6715 - val_accuracy: 0.7264\n",
      "Epoch 390/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6789 - accuracy: 0.7261 - val_loss: 0.6730 - val_accuracy: 0.7212\n",
      "Epoch 391/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6788 - accuracy: 0.7240 - val_loss: 0.6682 - val_accuracy: 0.7264\n",
      "Epoch 392/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6776 - accuracy: 0.7245 - val_loss: 0.6742 - val_accuracy: 0.7220\n",
      "Epoch 393/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6778 - accuracy: 0.7244 - val_loss: 0.6675 - val_accuracy: 0.7282\n",
      "Epoch 394/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6784 - accuracy: 0.7237 - val_loss: 0.6703 - val_accuracy: 0.7279\n",
      "Epoch 395/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6801 - accuracy: 0.7223 - val_loss: 0.6685 - val_accuracy: 0.7262\n",
      "Epoch 396/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6796 - accuracy: 0.7250 - val_loss: 0.6761 - val_accuracy: 0.7271\n",
      "Epoch 397/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6784 - accuracy: 0.7235 - val_loss: 0.6678 - val_accuracy: 0.7284\n",
      "Epoch 398/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6769 - accuracy: 0.7247 - val_loss: 0.6690 - val_accuracy: 0.7261\n",
      "Epoch 399/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6784 - accuracy: 0.7242 - val_loss: 0.6681 - val_accuracy: 0.7273\n",
      "Epoch 400/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6783 - accuracy: 0.7220 - val_loss: 0.6693 - val_accuracy: 0.7259\n",
      "Epoch 401/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6774 - accuracy: 0.7249 - val_loss: 0.6695 - val_accuracy: 0.7248\n",
      "Epoch 402/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6770 - accuracy: 0.7241 - val_loss: 0.6697 - val_accuracy: 0.7259\n",
      "Epoch 403/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6770 - accuracy: 0.7246 - val_loss: 0.6679 - val_accuracy: 0.7252\n",
      "Epoch 404/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6782 - accuracy: 0.7239 - val_loss: 0.6732 - val_accuracy: 0.7232\n",
      "Epoch 405/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6787 - accuracy: 0.7250 - val_loss: 0.6676 - val_accuracy: 0.7248\n",
      "Epoch 406/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6790 - accuracy: 0.7247 - val_loss: 0.6700 - val_accuracy: 0.7254\n",
      "Epoch 407/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6788 - accuracy: 0.7234 - val_loss: 0.6757 - val_accuracy: 0.7221\n",
      "Epoch 408/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6783 - accuracy: 0.7234 - val_loss: 0.6701 - val_accuracy: 0.7298\n",
      "Epoch 409/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6796 - accuracy: 0.7214 - val_loss: 0.6679 - val_accuracy: 0.7255\n",
      "Epoch 410/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6795 - accuracy: 0.7225 - val_loss: 0.6742 - val_accuracy: 0.7220\n",
      "Epoch 411/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6780 - accuracy: 0.7243 - val_loss: 0.6696 - val_accuracy: 0.7255\n",
      "Epoch 412/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6772 - accuracy: 0.7246 - val_loss: 0.6685 - val_accuracy: 0.7275\n",
      "Epoch 413/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6756 - accuracy: 0.7265 - val_loss: 0.6686 - val_accuracy: 0.7250\n",
      "Epoch 414/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6774 - accuracy: 0.7254 - val_loss: 0.6684 - val_accuracy: 0.7232\n",
      "Epoch 415/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6765 - accuracy: 0.7246 - val_loss: 0.6680 - val_accuracy: 0.7252\n",
      "Epoch 416/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6757 - accuracy: 0.7252 - val_loss: 0.6694 - val_accuracy: 0.7237\n",
      "Epoch 417/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6765 - accuracy: 0.7245 - val_loss: 0.6673 - val_accuracy: 0.7254\n",
      "Epoch 418/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6775 - accuracy: 0.7242 - val_loss: 0.6756 - val_accuracy: 0.7262\n",
      "Epoch 419/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6776 - accuracy: 0.7233 - val_loss: 0.6687 - val_accuracy: 0.7248\n",
      "Epoch 420/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6762 - accuracy: 0.7253 - val_loss: 0.6666 - val_accuracy: 0.7264\n",
      "Epoch 421/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6760 - accuracy: 0.7258 - val_loss: 0.6668 - val_accuracy: 0.7252\n",
      "Epoch 422/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6765 - accuracy: 0.7221 - val_loss: 0.6679 - val_accuracy: 0.7248\n",
      "Epoch 423/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6762 - accuracy: 0.7264 - val_loss: 0.6685 - val_accuracy: 0.7243\n",
      "Epoch 424/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6766 - accuracy: 0.7254 - val_loss: 0.6688 - val_accuracy: 0.7234\n",
      "Epoch 425/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6793 - accuracy: 0.7233 - val_loss: 0.6722 - val_accuracy: 0.7248\n",
      "Epoch 426/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6791 - accuracy: 0.7232 - val_loss: 0.6672 - val_accuracy: 0.7268\n",
      "Epoch 427/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6773 - accuracy: 0.7251 - val_loss: 0.6668 - val_accuracy: 0.7279\n",
      "Epoch 428/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6755 - accuracy: 0.7251 - val_loss: 0.6687 - val_accuracy: 0.7264\n",
      "Epoch 429/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6762 - accuracy: 0.7245 - val_loss: 0.6668 - val_accuracy: 0.7261\n",
      "Epoch 430/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6759 - accuracy: 0.7257 - val_loss: 0.6696 - val_accuracy: 0.7257\n",
      "Epoch 431/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6775 - accuracy: 0.7225 - val_loss: 0.6687 - val_accuracy: 0.7255\n",
      "Epoch 432/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6772 - accuracy: 0.7259 - val_loss: 0.6673 - val_accuracy: 0.7254\n",
      "Epoch 433/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6756 - accuracy: 0.7258 - val_loss: 0.6677 - val_accuracy: 0.7284\n",
      "Epoch 434/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6754 - accuracy: 0.7245 - val_loss: 0.6673 - val_accuracy: 0.7262\n",
      "Epoch 435/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6749 - accuracy: 0.7244 - val_loss: 0.6665 - val_accuracy: 0.7279\n",
      "Epoch 436/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6762 - accuracy: 0.7246 - val_loss: 0.6678 - val_accuracy: 0.7289\n",
      "Epoch 437/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6753 - accuracy: 0.7267 - val_loss: 0.6694 - val_accuracy: 0.7246\n",
      "Epoch 438/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6767 - accuracy: 0.7235 - val_loss: 0.6673 - val_accuracy: 0.7268\n",
      "Epoch 439/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6752 - accuracy: 0.7237 - val_loss: 0.6658 - val_accuracy: 0.7262\n",
      "Epoch 440/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6746 - accuracy: 0.7254 - val_loss: 0.6703 - val_accuracy: 0.7268\n",
      "Epoch 441/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6762 - accuracy: 0.7247 - val_loss: 0.6667 - val_accuracy: 0.7279\n",
      "Epoch 442/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6745 - accuracy: 0.7266 - val_loss: 0.6685 - val_accuracy: 0.7254\n",
      "Epoch 443/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6751 - accuracy: 0.7254 - val_loss: 0.6660 - val_accuracy: 0.7252\n",
      "Epoch 444/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6762 - accuracy: 0.7248 - val_loss: 0.6664 - val_accuracy: 0.7300\n",
      "Epoch 445/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6751 - accuracy: 0.7262 - val_loss: 0.6666 - val_accuracy: 0.7277\n",
      "Epoch 446/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6748 - accuracy: 0.7252 - val_loss: 0.6655 - val_accuracy: 0.7275\n",
      "Epoch 447/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6744 - accuracy: 0.7256 - val_loss: 0.6681 - val_accuracy: 0.7262\n",
      "Epoch 448/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6748 - accuracy: 0.7259 - val_loss: 0.6661 - val_accuracy: 0.7279\n",
      "Epoch 449/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6748 - accuracy: 0.7262 - val_loss: 0.6716 - val_accuracy: 0.7268\n",
      "Epoch 450/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6756 - accuracy: 0.7250 - val_loss: 0.6666 - val_accuracy: 0.7287\n",
      "Epoch 451/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6756 - accuracy: 0.7262 - val_loss: 0.6671 - val_accuracy: 0.7277\n",
      "Epoch 452/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6744 - accuracy: 0.7263 - val_loss: 0.6661 - val_accuracy: 0.7261\n",
      "Epoch 453/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6744 - accuracy: 0.7261 - val_loss: 0.6687 - val_accuracy: 0.7246\n",
      "Epoch 454/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6747 - accuracy: 0.7262 - val_loss: 0.6670 - val_accuracy: 0.7261\n",
      "Epoch 455/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6740 - accuracy: 0.7253 - val_loss: 0.6686 - val_accuracy: 0.7266\n",
      "Epoch 456/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6759 - accuracy: 0.7242 - val_loss: 0.6688 - val_accuracy: 0.7270\n",
      "Epoch 457/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6745 - accuracy: 0.7240 - val_loss: 0.6683 - val_accuracy: 0.7254\n",
      "Epoch 458/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6744 - accuracy: 0.7259 - val_loss: 0.6687 - val_accuracy: 0.7259\n",
      "Epoch 459/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6753 - accuracy: 0.7256 - val_loss: 0.6657 - val_accuracy: 0.7280\n",
      "Epoch 460/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6741 - accuracy: 0.7251 - val_loss: 0.6669 - val_accuracy: 0.7259\n",
      "Epoch 461/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6736 - accuracy: 0.7265 - val_loss: 0.6656 - val_accuracy: 0.7275\n",
      "Epoch 462/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6747 - accuracy: 0.7262 - val_loss: 0.6657 - val_accuracy: 0.7270\n",
      "Epoch 463/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6751 - accuracy: 0.7248 - val_loss: 0.6662 - val_accuracy: 0.7259\n",
      "Epoch 464/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6738 - accuracy: 0.7263 - val_loss: 0.6656 - val_accuracy: 0.7273\n",
      "Epoch 465/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6751 - accuracy: 0.7238 - val_loss: 0.6651 - val_accuracy: 0.7273\n",
      "Epoch 466/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6741 - accuracy: 0.7270 - val_loss: 0.6657 - val_accuracy: 0.7264\n",
      "Epoch 467/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6764 - accuracy: 0.7263 - val_loss: 0.6686 - val_accuracy: 0.7282\n",
      "Epoch 468/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6765 - accuracy: 0.7251 - val_loss: 0.6683 - val_accuracy: 0.7284\n",
      "Epoch 469/600\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.6741 - accuracy: 0.7248 - val_loss: 0.6666 - val_accuracy: 0.7284\n",
      "Epoch 470/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6738 - accuracy: 0.7261 - val_loss: 0.6661 - val_accuracy: 0.7259\n",
      "Epoch 471/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6744 - accuracy: 0.7260 - val_loss: 0.6667 - val_accuracy: 0.7262\n",
      "Epoch 472/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6755 - accuracy: 0.7245 - val_loss: 0.6649 - val_accuracy: 0.7279\n",
      "Epoch 473/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6764 - accuracy: 0.7242 - val_loss: 0.6665 - val_accuracy: 0.7286\n",
      "Epoch 474/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6756 - accuracy: 0.7238 - val_loss: 0.6681 - val_accuracy: 0.7255\n",
      "Epoch 475/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6753 - accuracy: 0.7260 - val_loss: 0.6653 - val_accuracy: 0.7257\n",
      "Epoch 476/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6741 - accuracy: 0.7259 - val_loss: 0.6672 - val_accuracy: 0.7296\n",
      "Epoch 477/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6765 - accuracy: 0.7225 - val_loss: 0.6702 - val_accuracy: 0.7245\n",
      "Epoch 478/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6738 - accuracy: 0.7269 - val_loss: 0.6663 - val_accuracy: 0.7286\n",
      "Epoch 479/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6740 - accuracy: 0.7251 - val_loss: 0.6660 - val_accuracy: 0.7266\n",
      "Epoch 480/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6743 - accuracy: 0.7266 - val_loss: 0.6714 - val_accuracy: 0.7270\n",
      "Epoch 481/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6749 - accuracy: 0.7250 - val_loss: 0.6665 - val_accuracy: 0.7275\n",
      "Epoch 482/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6734 - accuracy: 0.7271 - val_loss: 0.6649 - val_accuracy: 0.7270\n",
      "Epoch 483/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6725 - accuracy: 0.7257 - val_loss: 0.6675 - val_accuracy: 0.7261\n",
      "Epoch 484/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6730 - accuracy: 0.7255 - val_loss: 0.6655 - val_accuracy: 0.7271\n",
      "Epoch 485/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6740 - accuracy: 0.7258 - val_loss: 0.6678 - val_accuracy: 0.7248\n",
      "Epoch 486/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6747 - accuracy: 0.7263 - val_loss: 0.6674 - val_accuracy: 0.7257\n",
      "Epoch 487/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6766 - accuracy: 0.7245 - val_loss: 0.6734 - val_accuracy: 0.7245\n",
      "Epoch 488/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6745 - accuracy: 0.7251 - val_loss: 0.6649 - val_accuracy: 0.7264\n",
      "Epoch 489/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6753 - accuracy: 0.7254 - val_loss: 0.6662 - val_accuracy: 0.7264\n",
      "Epoch 490/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6726 - accuracy: 0.7268 - val_loss: 0.6646 - val_accuracy: 0.7270\n",
      "Epoch 491/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6732 - accuracy: 0.7267 - val_loss: 0.6654 - val_accuracy: 0.7293\n",
      "Epoch 492/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6737 - accuracy: 0.7271 - val_loss: 0.6651 - val_accuracy: 0.7261\n",
      "Epoch 493/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6756 - accuracy: 0.7235 - val_loss: 0.6645 - val_accuracy: 0.7271\n",
      "Epoch 494/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6771 - accuracy: 0.7246 - val_loss: 0.6668 - val_accuracy: 0.7279\n",
      "Epoch 495/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6741 - accuracy: 0.7235 - val_loss: 0.6658 - val_accuracy: 0.7282\n",
      "Epoch 496/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6747 - accuracy: 0.7259 - val_loss: 0.6679 - val_accuracy: 0.7287\n",
      "Epoch 497/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6725 - accuracy: 0.7279 - val_loss: 0.6645 - val_accuracy: 0.7284\n",
      "Epoch 498/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6727 - accuracy: 0.7280 - val_loss: 0.6676 - val_accuracy: 0.7250\n",
      "Epoch 499/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6726 - accuracy: 0.7252 - val_loss: 0.6683 - val_accuracy: 0.7254\n",
      "Epoch 500/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6749 - accuracy: 0.7257 - val_loss: 0.6659 - val_accuracy: 0.7268\n",
      "Epoch 501/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6733 - accuracy: 0.7262 - val_loss: 0.6665 - val_accuracy: 0.7257\n",
      "Epoch 502/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6734 - accuracy: 0.7258 - val_loss: 0.6660 - val_accuracy: 0.7287\n",
      "Epoch 503/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6732 - accuracy: 0.7274 - val_loss: 0.6690 - val_accuracy: 0.7252\n",
      "Epoch 504/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6732 - accuracy: 0.7275 - val_loss: 0.6647 - val_accuracy: 0.7262\n",
      "Epoch 505/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6743 - accuracy: 0.7267 - val_loss: 0.6660 - val_accuracy: 0.7271\n",
      "Epoch 506/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6734 - accuracy: 0.7267 - val_loss: 0.6657 - val_accuracy: 0.7277\n",
      "Epoch 507/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6728 - accuracy: 0.7257 - val_loss: 0.6648 - val_accuracy: 0.7275\n",
      "Epoch 508/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6725 - accuracy: 0.7258 - val_loss: 0.6641 - val_accuracy: 0.7280\n",
      "Epoch 509/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6723 - accuracy: 0.7274 - val_loss: 0.6663 - val_accuracy: 0.7300\n",
      "Epoch 510/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6727 - accuracy: 0.7274 - val_loss: 0.6659 - val_accuracy: 0.7266\n",
      "Epoch 511/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6725 - accuracy: 0.7266 - val_loss: 0.6670 - val_accuracy: 0.7284\n",
      "Epoch 512/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6725 - accuracy: 0.7263 - val_loss: 0.6646 - val_accuracy: 0.7300\n",
      "Epoch 513/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6722 - accuracy: 0.7270 - val_loss: 0.6649 - val_accuracy: 0.7295\n",
      "Epoch 514/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6723 - accuracy: 0.7271 - val_loss: 0.6649 - val_accuracy: 0.7273\n",
      "Epoch 515/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6727 - accuracy: 0.7258 - val_loss: 0.6656 - val_accuracy: 0.7264\n",
      "Epoch 516/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6754 - accuracy: 0.7249 - val_loss: 0.6699 - val_accuracy: 0.7241\n",
      "Epoch 517/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6753 - accuracy: 0.7260 - val_loss: 0.6648 - val_accuracy: 0.7287\n",
      "Epoch 518/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6729 - accuracy: 0.7265 - val_loss: 0.6666 - val_accuracy: 0.7255\n",
      "Epoch 519/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6733 - accuracy: 0.7257 - val_loss: 0.6636 - val_accuracy: 0.7296\n",
      "Epoch 520/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6722 - accuracy: 0.7266 - val_loss: 0.6660 - val_accuracy: 0.7270\n",
      "Epoch 521/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6719 - accuracy: 0.7271 - val_loss: 0.6646 - val_accuracy: 0.7280\n",
      "Epoch 522/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6731 - accuracy: 0.7251 - val_loss: 0.6652 - val_accuracy: 0.7275\n",
      "Epoch 523/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6735 - accuracy: 0.7254 - val_loss: 0.6677 - val_accuracy: 0.7248\n",
      "Epoch 524/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6737 - accuracy: 0.7254 - val_loss: 0.6647 - val_accuracy: 0.7291\n",
      "Epoch 525/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6724 - accuracy: 0.7278 - val_loss: 0.6655 - val_accuracy: 0.7270\n",
      "Epoch 526/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6728 - accuracy: 0.7266 - val_loss: 0.6665 - val_accuracy: 0.7266\n",
      "Epoch 527/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6734 - accuracy: 0.7269 - val_loss: 0.6654 - val_accuracy: 0.7279\n",
      "Epoch 528/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6736 - accuracy: 0.7242 - val_loss: 0.6648 - val_accuracy: 0.7295\n",
      "Epoch 529/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6731 - accuracy: 0.7269 - val_loss: 0.6698 - val_accuracy: 0.7282\n",
      "Epoch 530/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6737 - accuracy: 0.7257 - val_loss: 0.6668 - val_accuracy: 0.7266\n",
      "Epoch 531/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6728 - accuracy: 0.7267 - val_loss: 0.6713 - val_accuracy: 0.7266\n",
      "Epoch 532/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6742 - accuracy: 0.7241 - val_loss: 0.6643 - val_accuracy: 0.7284\n",
      "Epoch 533/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6733 - accuracy: 0.7270 - val_loss: 0.6641 - val_accuracy: 0.7275\n",
      "Epoch 534/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6730 - accuracy: 0.7246 - val_loss: 0.6661 - val_accuracy: 0.7270\n",
      "Epoch 535/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6721 - accuracy: 0.7277 - val_loss: 0.6655 - val_accuracy: 0.7280\n",
      "Epoch 536/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6720 - accuracy: 0.7263 - val_loss: 0.6662 - val_accuracy: 0.7287\n",
      "Epoch 537/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6732 - accuracy: 0.7252 - val_loss: 0.6644 - val_accuracy: 0.7277\n",
      "Epoch 538/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6726 - accuracy: 0.7276 - val_loss: 0.6654 - val_accuracy: 0.7293\n",
      "Epoch 539/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6717 - accuracy: 0.7271 - val_loss: 0.6652 - val_accuracy: 0.7312\n",
      "Epoch 540/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6720 - accuracy: 0.7265 - val_loss: 0.6636 - val_accuracy: 0.7289\n",
      "Epoch 541/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6717 - accuracy: 0.7274 - val_loss: 0.6635 - val_accuracy: 0.7277\n",
      "Epoch 542/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6718 - accuracy: 0.7268 - val_loss: 0.6647 - val_accuracy: 0.7273\n",
      "Epoch 543/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6714 - accuracy: 0.7270 - val_loss: 0.6642 - val_accuracy: 0.7271\n",
      "Epoch 544/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6717 - accuracy: 0.7265 - val_loss: 0.6644 - val_accuracy: 0.7261\n",
      "Epoch 545/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6727 - accuracy: 0.7267 - val_loss: 0.6662 - val_accuracy: 0.7277\n",
      "Epoch 546/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6730 - accuracy: 0.7267 - val_loss: 0.6655 - val_accuracy: 0.7286\n",
      "Epoch 547/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6720 - accuracy: 0.7279 - val_loss: 0.6668 - val_accuracy: 0.7261\n",
      "Epoch 548/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6724 - accuracy: 0.7275 - val_loss: 0.6650 - val_accuracy: 0.7298\n",
      "Epoch 549/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6715 - accuracy: 0.7272 - val_loss: 0.6631 - val_accuracy: 0.7282\n",
      "Epoch 550/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6736 - accuracy: 0.7240 - val_loss: 0.6655 - val_accuracy: 0.7257\n",
      "Epoch 551/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6729 - accuracy: 0.7257 - val_loss: 0.6689 - val_accuracy: 0.7268\n",
      "Epoch 552/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6730 - accuracy: 0.7251 - val_loss: 0.6666 - val_accuracy: 0.7295\n",
      "Epoch 553/600\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.6727 - accuracy: 0.7255 - val_loss: 0.6643 - val_accuracy: 0.7296\n",
      "Epoch 554/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6730 - accuracy: 0.7250 - val_loss: 0.6656 - val_accuracy: 0.7282\n",
      "Epoch 555/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6717 - accuracy: 0.7279 - val_loss: 0.6653 - val_accuracy: 0.7270\n",
      "Epoch 556/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6708 - accuracy: 0.7282 - val_loss: 0.6648 - val_accuracy: 0.7259\n",
      "Epoch 557/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6728 - accuracy: 0.7262 - val_loss: 0.6660 - val_accuracy: 0.7266\n",
      "Epoch 558/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6710 - accuracy: 0.7276 - val_loss: 0.6638 - val_accuracy: 0.7291\n",
      "Epoch 559/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6720 - accuracy: 0.7291 - val_loss: 0.6642 - val_accuracy: 0.7286\n",
      "Epoch 560/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6745 - accuracy: 0.7272 - val_loss: 0.6676 - val_accuracy: 0.7286\n",
      "Epoch 561/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6714 - accuracy: 0.7257 - val_loss: 0.6647 - val_accuracy: 0.7289\n",
      "Epoch 562/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6710 - accuracy: 0.7278 - val_loss: 0.6636 - val_accuracy: 0.7282\n",
      "Epoch 563/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6727 - accuracy: 0.7255 - val_loss: 0.6704 - val_accuracy: 0.7227\n",
      "Epoch 564/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6738 - accuracy: 0.7243 - val_loss: 0.6665 - val_accuracy: 0.7305\n",
      "Epoch 565/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6723 - accuracy: 0.7263 - val_loss: 0.6727 - val_accuracy: 0.7254\n",
      "Epoch 566/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6740 - accuracy: 0.7244 - val_loss: 0.6674 - val_accuracy: 0.7250\n",
      "Epoch 567/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6723 - accuracy: 0.7262 - val_loss: 0.6656 - val_accuracy: 0.7282\n",
      "Epoch 568/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6724 - accuracy: 0.7260 - val_loss: 0.6664 - val_accuracy: 0.7287\n",
      "Epoch 569/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6714 - accuracy: 0.7271 - val_loss: 0.6657 - val_accuracy: 0.7262\n",
      "Epoch 570/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6731 - accuracy: 0.7258 - val_loss: 0.6668 - val_accuracy: 0.7270\n",
      "Epoch 571/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6730 - accuracy: 0.7267 - val_loss: 0.6640 - val_accuracy: 0.7246\n",
      "Epoch 572/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6715 - accuracy: 0.7280 - val_loss: 0.6635 - val_accuracy: 0.7277\n",
      "Epoch 573/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6714 - accuracy: 0.7283 - val_loss: 0.6655 - val_accuracy: 0.7277\n",
      "Epoch 574/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6716 - accuracy: 0.7256 - val_loss: 0.6634 - val_accuracy: 0.7275\n",
      "Epoch 575/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6714 - accuracy: 0.7275 - val_loss: 0.6638 - val_accuracy: 0.7300\n",
      "Epoch 576/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6715 - accuracy: 0.7275 - val_loss: 0.6648 - val_accuracy: 0.7268\n",
      "Epoch 577/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6714 - accuracy: 0.7293 - val_loss: 0.6650 - val_accuracy: 0.7302\n",
      "Epoch 578/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6714 - accuracy: 0.7265 - val_loss: 0.6636 - val_accuracy: 0.7271\n",
      "Epoch 579/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6723 - accuracy: 0.7254 - val_loss: 0.6666 - val_accuracy: 0.7264\n",
      "Epoch 580/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6711 - accuracy: 0.7271 - val_loss: 0.6642 - val_accuracy: 0.7293\n",
      "Epoch 581/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6727 - accuracy: 0.7258 - val_loss: 0.6692 - val_accuracy: 0.7245\n",
      "Epoch 582/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6712 - accuracy: 0.7266 - val_loss: 0.6685 - val_accuracy: 0.7277\n",
      "Epoch 583/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6722 - accuracy: 0.7263 - val_loss: 0.6663 - val_accuracy: 0.7246\n",
      "Epoch 584/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6709 - accuracy: 0.7267 - val_loss: 0.6654 - val_accuracy: 0.7270\n",
      "Epoch 585/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6715 - accuracy: 0.7258 - val_loss: 0.6646 - val_accuracy: 0.7291\n",
      "Epoch 586/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6712 - accuracy: 0.7271 - val_loss: 0.6638 - val_accuracy: 0.7282\n",
      "Epoch 587/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6705 - accuracy: 0.7273 - val_loss: 0.6665 - val_accuracy: 0.7293\n",
      "Epoch 588/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6710 - accuracy: 0.7282 - val_loss: 0.6643 - val_accuracy: 0.7270\n",
      "Epoch 589/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6715 - accuracy: 0.7266 - val_loss: 0.6637 - val_accuracy: 0.7271\n",
      "Epoch 590/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6708 - accuracy: 0.7274 - val_loss: 0.6635 - val_accuracy: 0.7298\n",
      "Epoch 591/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6706 - accuracy: 0.7275 - val_loss: 0.6664 - val_accuracy: 0.7279\n",
      "Epoch 592/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6727 - accuracy: 0.7285 - val_loss: 0.6630 - val_accuracy: 0.7282\n",
      "Epoch 593/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6741 - accuracy: 0.7262 - val_loss: 0.6640 - val_accuracy: 0.7307\n",
      "Epoch 594/600\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6724 - accuracy: 0.7256 - val_loss: 0.6733 - val_accuracy: 0.7254\n",
      "Epoch 595/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6715 - accuracy: 0.7258 - val_loss: 0.6662 - val_accuracy: 0.7280\n",
      "Epoch 596/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6699 - accuracy: 0.7267 - val_loss: 0.6633 - val_accuracy: 0.7302\n",
      "Epoch 597/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6706 - accuracy: 0.7271 - val_loss: 0.6639 - val_accuracy: 0.7268\n",
      "Epoch 598/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6719 - accuracy: 0.7258 - val_loss: 0.6650 - val_accuracy: 0.7262\n",
      "Epoch 599/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6708 - accuracy: 0.7274 - val_loss: 0.6628 - val_accuracy: 0.7293\n",
      "Epoch 600/600\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6706 - accuracy: 0.7276 - val_loss: 0.6640 - val_accuracy: 0.7273\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x25cf6202590>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=X_train, \n",
    "          y=y_cat_train, \n",
    "          epochs=600,\n",
    "          batch_size = 1024,\n",
    "          validation_data=(X_test, y_cat_test), verbose=1\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "aff25564-4886-46b7-85b1-8743450fbafc",
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = pd.DataFrame(model.history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d9613b2e-26e5-4122-96b7-f3b4fe6bc99b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.945365</td>\n",
       "      <td>0.148795</td>\n",
       "      <td>1.944656</td>\n",
       "      <td>0.136607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.943380</td>\n",
       "      <td>0.144420</td>\n",
       "      <td>1.941978</td>\n",
       "      <td>0.136607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.939416</td>\n",
       "      <td>0.137009</td>\n",
       "      <td>1.935302</td>\n",
       "      <td>0.161250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.929062</td>\n",
       "      <td>0.194196</td>\n",
       "      <td>1.919132</td>\n",
       "      <td>0.279643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.908387</td>\n",
       "      <td>0.285268</td>\n",
       "      <td>1.889861</td>\n",
       "      <td>0.290000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>0.669882</td>\n",
       "      <td>0.726652</td>\n",
       "      <td>0.663250</td>\n",
       "      <td>0.730179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>0.670594</td>\n",
       "      <td>0.727054</td>\n",
       "      <td>0.663945</td>\n",
       "      <td>0.726786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>0.671932</td>\n",
       "      <td>0.725759</td>\n",
       "      <td>0.665050</td>\n",
       "      <td>0.726250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>0.670764</td>\n",
       "      <td>0.727366</td>\n",
       "      <td>0.662843</td>\n",
       "      <td>0.729286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>0.670605</td>\n",
       "      <td>0.727634</td>\n",
       "      <td>0.663966</td>\n",
       "      <td>0.727321</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>600 rows  4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         loss  accuracy  val_loss  val_accuracy\n",
       "0    1.945365  0.148795  1.944656      0.136607\n",
       "1    1.943380  0.144420  1.941978      0.136607\n",
       "2    1.939416  0.137009  1.935302      0.161250\n",
       "3    1.929062  0.194196  1.919132      0.279643\n",
       "4    1.908387  0.285268  1.889861      0.290000\n",
       "..        ...       ...       ...           ...\n",
       "595  0.669882  0.726652  0.663250      0.730179\n",
       "596  0.670594  0.727054  0.663945      0.726786\n",
       "597  0.671932  0.725759  0.665050      0.726250\n",
       "598  0.670764  0.727366  0.662843      0.729286\n",
       "599  0.670605  0.727634  0.663966      0.727321\n",
       "\n",
       "[600 rows x 4 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "711e5bf6-1c2f-4149-86ad-c244e06f88a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# loss --> Training loss, val_loss--> Test data loss\n",
    "losses[['loss','val_loss']].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8a4e47f1-59f2-4ab7-b418-ef971824fb69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiMAAAGdCAYAAADAAnMpAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAABWoElEQVR4nO3dd3hUVeL/8feUZNIDSUggECD0EhBIpKqIKC4oK+IqNhTLKuvalrWx/uy66H4t6K6gYGVFRQVcVCxBEUGsgdB7CySBkEA6aTP398cNAyEJZELIpHxezzNPZm49c4zcT84591yLYRgGIiIiIl5i9XYBREREpHlTGBERERGvUhgRERERr1IYEREREa9SGBERERGvUhgRERERr1IYEREREa9SGBERERGvsnu7ADXhcrlIS0sjODgYi8Xi7eKIiIhIDRiGQV5eHtHR0Vit1bd/NIowkpaWRkxMjLeLISIiIrWwd+9e2rVrV+36RhFGgoODAfPLhISEeLk0IiIiUhO5ubnExMS4r+PVaRRh5GjXTEhIiMKIiIhII3OqIRYawCoiIiJepTAiIiIiXqUwIiIiIl7VKMaM1IRhGJSVleF0Or1dFGnAfHx8sNls3i6GiIgcp0mEkZKSEtLT0yksLPR2UaSBs1gstGvXjqCgIG8XRUREyjX6MOJyudi1axc2m43o6Gh8fX01MZpUyTAMDh48yL59++jatataSEREGohGH0ZKSkpwuVzExMQQEBDg7eJIA9eqVSt2795NaWmpwoiISAPRZAawnmyaWZGj1GomItLw6AouIiIiXqUwIiIiIl6lMCIiIiJepTAibqWlpd4ugoiINEMKI1701Vdfcc4559CiRQvCw8O59NJL2bFjh3v9vn37uPrqqwkLCyMwMJCEhAR++eUX9/pFixaRkJCAn58fERERjB8/3r3OYrHw6aefVjhfixYteOeddwDYvXs3FouFjz76iPPPPx8/Pz/ee+89srKyuOaaa2jXrh0BAQH06dOHDz74oMJxXC4Xzz33HF26dMHhcNC+fXueeeYZAC644ALuvPPOCttnZWXhcDj47rvv6qLaREQapqwd8MPzUJx3+sdylkFJwekf50T5ByHvQN0f9zQ1uTBiGAaFJWVeeRmG4VFZCwoKmDJlCr/99hvffvstVquVyy+/HJfLRX5+PsOHDyctLY1FixaxZs0aHnjgAVwuFwBffPEF48eP55JLLmH16tV8++23JCQkeFxfDz74IHfffTebNm3i4osvpqioiPj4eD7//HPWr1/PbbfdxsSJEyuEoKlTp/Lcc8/xyCOPsHHjRt5//32ioqIAuPXWW3n//fcpLi52bz937lyio6MZMWKEx+UTkVMoK4bP7oGN/6vb4x7eDUeyK5/roxvg26cqLi/Krbvz/vYGrJkHNfn39PBu83sf3bY4D4pyKm5zJLvisQoy4b0r4MeXYdHdMOcy2P2jua6kEFJ+gcRHj32nw3vgwAbz/Y6lsPo9KP932K2sGPL2w9w/wXdPwTePVFxvGPD727DoLijOh10/mOdO/sBcZxiU7ljOhvWrMQ5uNQPDgj/DCz3M85eVVK7j3T/C7AsofbYT2W+Oh0O7YNPnx9Zn7TC/y7pPzOMt/Av8NANj5lCYOQQSH4N/x0PGZlg9t3K91TOL4ekV1Atyc3MJDQ0lJyeHkJCQCuuKiorYtWsXsbGx+Pn5UVhSRq9Hv/ZKOTc+eTEBvrWfuuXgwYNERkaybt06Vq5cyX333cfu3bsJCwurtO3QoUPp1KkT7733XpXHslgsLFy4kHHjxrmXtWjRgunTpzNp0iR2795NbGws06dP55577jlpuS655BJ69uzJ888/T15eHq1ateI///kPt956a6Vti4uLiY6OZubMmVx11VUA9O/fn3HjxvHYY495UBtnxom/LyJnXG462B0QUPn/4wr2JUHLDhAYAXt/g2/+H0T3g5YdIekdOPtW6HwBhHeuuF/SO2YYAXgkC7Z+BZE9K293IpcLVr1jXuSG3gVWm1mG+TeDIxj2r4fWfeD2HyB7D/z+FviHwZLy/48H/QX8QuCnGVCSB0PuhIueAqvVPKbdAclzIXUVxAyCNn3B5sDI2ETp3t/x3bLI/Mt/aPkF+tdZ0GGoWf6jxjwPjmByAjsS2ra7eeE+Wo+lRzD+czaWnL0U9b8Zv/xUjB3fgauMr1pcQ+yEZ+lx4Av49C8k9ZqKq91AEop+ho2fYsncUqEqnD5BWCfOxzL3Sig+dtEvjf8z9rVzMcqK2d3jNmI3v47FcEG/68FZgvPgFvJb9MB3xzf4lx6ucMz9fe/At/cYwg78DN897V5e3HYwjsyN7vP8L/R69hPB7TnTj5XHYsNmlD/aJKoP5KVhlB6hcMLHLN9xmENJ/+Pako+r/u/a41Lody3MvxVKaz4r+c6gAdgnfUb7iLqdnfpk1+/jKYzUIU/DyI4dO3jkkUf4+eefyczMxOVyUVBQwBdffMHnn3/Ohg0bWLZsWZX7BgQE8Oqrr3LTTTdVub6mYWTFihUMGzbMvY3T6eTZZ59l3rx5pKamUlxcTHFxMZdffjkfffQRv/76K4MGDWLnzp3ExsZWee577rmHLVu28NVXX5GcnMyAAQPYtWsXHTp0qHHdnCkKI02UYcChnRDWCU41l8yRbHCWguGCfb9C90vMCyiYf7EGRUGr7tXvv/N7CAg3L9RVcbngl5ngCIFuf4B/DwCrHW5cdGyffb/D/nUQP8m80Cc+Bhs/pcwnmAN+nWibt6bqY1uscP5U8AmAftdSihWfrx6EtR+a6+OugPXzOWiN5OvhCxl3dif813+AbetiinIz2RoymLmOCeQWG7wQ9B4ByW8BUBw9kF0hZ9Nj86snr7tT2OAXj4/NQtfCVeZFu445LXY+bnErFwfvxD/1J/yc1XeHHLRE0MrIrPMynEypYWOn0Ybu1n31et66sqbPPzjrigfr9Jg1DSONfgbWE/n72Nj45MVeO7cnxo4dS0xMDLNnzyY6OhqXy0VcXBwlJSX4+/uf/FynWG+xWCp1G1U1QDUwMLDC5xdeeIGXXnqJ6dOn06dPHwIDA7n33nspKSmp0XnB7Krp168f+/bt46233mLkyJENIohII+dyQvL75l/txbnmX6dWK6Qlw2+zzebz3pfD5bNg/1qI7GVevK1286/+nd+brQzvXQGFmZSFxGDPWA8XPmG2OHxyE2RtB5sveaNe5FBob+xBEWz5LZEBrnXsyy6hQwsfgte9g2Gxkd7rVnYF96ewRXfOC05j3vp8IoIcjAncCt//0ywyFqyY/x8WzBrDGlsvuoT5EnngBwCMZf/Ckpfm/or20jzallYTRMAMUEvN8Vl88zA+J65fPx+AVq4Mrl86DJYeW+UH9M1IJsz4hDzDnwDrXvc6R9qv9Ej7tcb/Kda7OhJrSSfQYnbHprha0d56kN5FSTU+xsyysfS3bmewddNJt9vliqKdJRMfixObUcbVh1+Dw5W3e7/sAt5y/oF/+/yHntaUKoPIEmd/9hqRFOPDZPvnvFZ2KR85z2eO77O0s1Tc/oDRgihLdoVlnzsH8ZurB//P/h4+FicHjBaUYmeRcyh7jVbscEWzxtqTK5zfMsKazAjrauyWqkPZTSX308mSziM+Zuv2dqMtr3efzbdrU1jlN/mkdQLwYdn59LPuoLM1nWLDTpClqNI2N5fcxzDf7VxqfM9aurEr7Fx8Dq7nJrv5B/s+I8L9vdP9uxLQzXtd6U0ujFgsltPqKqkvWVlZbNq0iddff51zzz0XgBUrVrjX9+3blzfeeINDhw5V2U3Tt29fvv3222pbRlq1akV6err787Zt22r0IMHly5dz2WWXcf311wPmYNVt27bRs2dPALp27Yq/vz/ffvttld00AH369CEhIYHZs2fz/vvv8+9///uU55UmyjDMloq8/bBhIfS/Hqw+sH0JxJ5nNvOXFpGXmULhsn8T0vcS/J354NcCZ+eR2DI3w8LJGHFXYJQUYF327LFjL7qLnNZDCcn4DYurPGhvWGi+jlPk25ICSyDhxRX/WrUf7SNf8tixrgcAZwnBX95JcPnHtuU/WwCUX78thpPoDa8Tfdzxbqji67uDiOEg0JXLUNfPcNzYweODSFUuK36SPALIN/yJt27lYttvjLOtPOk+p9LOkgnljUdvlI1mrvNCzrWuZYB1G50tafzo6sP3rrOIJJtXfP/DGlcnHi+9kRjLQe63zyODllxXMpVOQWUMaWPh5/wodmYW8lrbbxmeOotNPr15oeAP/Nn+BVtcMaT5tOeQbzRHXD4EFe5hvvM8oi2Z2Ft15Z2MFK73W86PJV0pMPy4276AaEsWva17+NnVk9tKppBLIAP89nN70A9clP8/d52+bx1LybD7cGbt5PPVKaw2ugKwMubPdEt7gnRakdmiDwGWMjpa92MZ8Q9KXAms35RB//YtcPb9D4MyYaTDTmZqX9otGgVAmn93Po25n8COZ+Pz9YNMsHzDG53/zdCBA7nz7a2AhRWO88gqLCO7/LckvkNL7FYLPVsHM/ui7hSWXkBUsB8Fe9eSl7GbgE5DaJG6jJlpsZSu+Dc/uXqzytqHX6wWevcZxpCgdHz7XMtzrVszo3Uk/HDsv1exYWeOMZoWQ29mwObn6Zz9I0UXPEnywRG07BFJj96tWb4hlRUrvuf+Aw/g78oHYFX7mxgVdyMTzo6huMzFucBFPja2pqSx8eNb2RmSQPRFd/HL6u+J6RLHwF5dwFYp3tabJtdN01i4XC4iIyMZPXo0jz32GCkpKTz00EP89ttvLFy4kDFjxtCnTx+ioqKYNm0abdq0YfXq1URHRzNkyBC+//57Ro4cyf/7f/+Pq6++mrKyMr788kseeOABAK655hrWrFnDe++9h8vl4sEHH2T58uXMmjWrQjfN6tWr6devn7tcf/vb35g/fz4ffvghLVu25MUXX+Sjjz5ixIgR7rtznnjiCV5++WWmT5/OsGHDOHjwIBs2bOCWW25xH2f27NnceeedBAQEkJ6e3mD+2zTW35cGIXWVOW7ggkcgOOqkmx48kMqKBTMYe/AN8hyRhBalYjWcFPuE4GsxsJTkURocQ861XxC06Bb80n+rdIzj/2qrL0udZ7HLaMPN9q+q3WZu2UiK8eEG2zfV/tV7xPBlcfiNjM16ixwCGV/yBAMde3GU5hBEIa0sOUywLSXEcsS9T6+it9jod3OF43Qseh8Ah91KcZl5rhDyuaOfL9dsv49S/wgi8jZX2Of7iGsZ1taKz5r3KA7rzsaOk3gqpTcWVxnr03K52Pob9/ktIsnVmYfL/syr1w8kr7iMuz9YDcD8vwzhQG4xZU4XZQc2M2MtJHRqxaRhHekWGUx+SRkOuxWH/VhLcJnThd1mhUM7cYW0Z8Ga/azZm80V8e3oF9MCAKfLIC37CDOX7WBs32gGdwojI6+YVkEONqbn8vWG/aQcKqRNqD+//PAV/m268/7doylzurBZLeajHIrzOJSTx77dW+idcD42q4WMvCJuevs3NqTlMrhTGNMn9Kd1iOPU3XUncG1NxFWUi73vFcctdJnjYfxCAfhlZxYH84u5tG80K7dnsj+3iJ5tQujUKrBCfVSnsKSMmd/v4OLerYlrG1r9hovuhlXvsqP/VHZ1mUTfmBZEhviZ5Tm42RwTVNX3y9ph/gHgLKl+m3rWbMeMNCZLlizh7rvvZufOnXTv3p1XXnmF888/3z3WY8+ePfz9738nMTGRsrIyevXqxauvvsrAgQMBWLBgAU899RQbN24kJCSE8847j/nzzWbatLQ0brrpJn788Ueio6N5+eWXueaaayqNGTkxjBw6dIibb76Zb7/9loCAAG677TZSUlLIyclxhxGXy8W0adOYPXs2aWlptGnThsmTJzN16lT3cfLz84mKimLSpEm8+urp9UPXpcb8+3KmuVwGFgtYXGVmc//SfwIGR5xWDjuiaZO9CktZEdv8+zG7zePc0WYz/zvUnqF7XiP2yHqKLP78PnIeSzbs419pkwigcrPxiXKNAEIsNR9kdyov2W/hb2VvVli2ydadKEs2G8JH0b14PX5FB1lNN4YWL2dLt8mUuQycKb+yMupavszrwsb0XK4M2cA9fV3k5OUR29KX3d1u4sHPdlKwfxuH/drz2d3n8sT/1hK/779MLnuPnYH9cE14j6Clj9J61wLWDniKPmPvIu1gFtuzSoiNbEF0Cz9sVgub0vPo1CqQ93/eQ/tvbuZC22retY3nun+8CZ/cjH3TQmg/FIbdw8LCOPzsNkb3aUNOYSlPfLaBET0iGXtWtHlhslph1Rx+35XFu2vyuTViPXG3vo7Nv/xCd8LF6KcdWXy+No1/jOmJw27FZYCv3RwvszrlMDlHSjm/e2Sd/feoDcMw+HL9fs6KaUHbFqfuFm6Syoph7y/QYZjZxdiIKYyIV+3du5eOHTvy22+/MWDAAG8Xx61J/744y6DgoDkA88A6c8yEzcc9dsgCsOpds4vkwicwinKxhETjWvkKa/ccJGXfPoZZ1hFuqf1tmr+6ujPQWvFOhVfKxhFGHtfbv63xcb5zxTPAuo3XbFfzkHNWldv8dP77DMr9mnll59MzfQFBPS6k3TnXYk16kzXOWDoHHMHmLCB04PVVn8RZBraKXbqlThc/7cjirJgWhPpXbLLOyi/mu80ZXNAjkvAgx7FjrPsYOo+A4Nbm54ObIap3jf4qfe3r1exa/iEjr7yDUWd1MAfWlhWZ42I85HQZ2Kze/0tY5HgKI+IVpaWlpKen89BDD7Fnzx5+/PFHbxepgkb9+5LyC7jKoOOwistTV5m3SC5/AXYuNW+/PHII2sZDzCBS1//ArNxB3D4gkOjkV2p8uq+cZ9PekkEv655TbrvWFUtf664Ky1xWH9YOfonltsG8kLiVK23fM9y6hl1GG75yDmRB27k4Ms35G4wWHbBkm+cpiepH9vVfExlc/t/npxnw9VSzeyg0BhbehuvSV7Am3Fjj79KQuVwGVoUIaaKa7d004l0//vgjI0aMoFu3bnzyySfeLk7jlLMPFk427/y4+Bmzvzo/A94yB9il9phECyOPnLgbCEqaQcjuE25lP3LI/JmaBKlJtAWesK6H5JoXYXzx46wyuuFLKX3t+5g4ahDZP8/hjcP9mRG7kj5pH1NqdWB3lYB/GMXDp8NXlx07wJ/exho3nn5AP6BTqyAe/8xBz+F38OrXm7l2aAccw8fDl/dDr3FY4q6A7BT4cTq+591/LIgADLrdDGBRfczWhi4jsQaEe1ipDZeCiIhaRqSZafC/L2s/MmdePKrzBRB/kzkfxsqT35VUZlixW1yUGjZeKvsTbSxZDLZuoqs11b3NISOI8SVPEEU2HeOG4FN0kOjcNfwl92UsRydZuvZj6DaKnCOlzE/ax3ndIugSGUxRqZN1qTkktAvEsuZDs2z5B8ywFNHVnOlx+xLodx3EnlttOZ0uA6vFvPNNRJo2ddOIVMFrvy/ZKfDL63DOFAgs/6u+OB98A83R7zu+NX/Ov6XCDJA18beSv/CTqxc5BNLKXkjXlnZ20Ya07CP0ahPCdfGR9LTuZcfGJFbmtuKXko68dFU/ziq/y8Htx1fg0A4Y80KlsRQiIrWhbhqRhuSTW8zWjZSf4M/fwWf3QtLb5rqg1pC/v8Lmz8TO4cId/2SQdXPlY5UrNBxc4nqBmC7duTg8AIePjasSYugSWdV0zl3pdfYFjD1ZGYfd7em3EhGpEwojIvVhX/nslqlJZotI8txj604IInNjHmf2Jjsfch/tLQcIt+TyuP1dEl3x3G7/ghwjkK/O+ZgJA1qz9FTPHxERaQRqFUZmzJjB//3f/5Genk7v3r2ZPn26exbRE02aNIl333230vJevXqxYcOG2pxepHHIP2jO19H/evBrAUXZ5vLF95mTEh3nP73fJ3vjUlYVtWXVtm4A5BHAQzdPoENYIGFBD3C7ww7bvyUkvAsTWmp6fRFpOjwOI/PmzePee+9lxowZDBs2jNdff53Ro0ezceNG2rdvX2n7l19+mWefPTaFc1lZGWeddRZXXnnl6ZVcpKH76iFY/wlsT6w4DmTNBwAUtR2KJfV3FpUN5vkkgGPPhbj1nFgevqRn5UGeXUaiYZ8i0tR4PIB10KBBDBgwgJkzZ7qX9ezZk3HjxjFt2rRT7v/pp58yfvx4j57iqgGsUlfq5ffFMMwZFJ+pPGW6q9c4rBs/5aAtiuuMp9lXaMNl8+OP/duRcqiQi3u35oYhHTV5lYg0CWdkAGtJSQlJSUk89NBDFZaPGjWKlStr9vCmN998kwsvvPCkQeToY+uPys2t/YyQIvUqfQ18dCMc3lXl6nfaPMZXq/uwxYghh0B8bVYW33MOXSI9n3FTRKSpsHqycWZmJk6nk6ioin/xRUVFsX///mr2OiY9PZ0vv/yy2qe9HjVt2jRCQ0Pdr5iYGE+K2Wx07NiR6dOne7sYclTaanj9vIpBpNtoc54QYEfw2byQuJVfjZ4M6B7LXRd0YcEdQxVERKTZq9UA1hP7sQ3DqNEERu+88w4tWrRg3LhxJ91u6tSpTJkyxf05NzdXgUQatsztMOv8Y599AiC8C5sSnua55ZkElQSRnNmFAsNJ//YtmHVDAj42j/4WEBFpsjwKIxEREdhstkqtIBkZGZVaS05kGAZvvfUWEydOxNfX96TbOhwOHA6HJ0WTRsbpdGKxWLBam8gF+ZfXjr0f+SgMvYcD+aVc9dIP5BWVAUM4t2sET50Ty7ldIszHrYuICOBhN42vry/x8fEkJiZWWJ6YmMjQoUNPuu+yZcvYvn07t9xyi+el9IRhmA8N88bLg7HAr7/+Om3btsXlclVY/sc//pEbb7yRHTt2cNlllxEVFUVQUBBnn302S5YsqXW1vPjii/Tp04fAwEBiYmK44447yM/Pr7DNjz/+yPDhwwkICKBly5ZcfPHFHD58GACXy8Vzzz1Hly5dcDgctG/fnmeeeQaA77//HovFQnZ2tvtYycnJWCwWdu/eDRxrFfv888/p1asXDoeDPXv28Ntvv3HRRRcRERFBaGgow4cPZ9WqVRXKlZ2dzW233UZUVBR+fn7ExcXx+eefU1BQQEhISKVn4Hz22WcEBgaSl5dX6/ry2Nby58Nc9wnOYVOY9eMeRk1fXh5EYEincN64MYER3SMVRERETuBxN82UKVOYOHEiCQkJDBkyhFmzZpGSksLkyZMBs4slNTWVOXPmVNjvzTffZNCgQcTFxdVNyatTWgj/jD6z56jOP9LM6b1r4Morr+Tuu+9m6dKljBw5EoDDhw/z9ddf89lnn5Gfn8+YMWN4+umn8fPz491332Xs2LFs2bKlyluoT8VqtfLKK6/QsWNHdu3axR133MEDDzzAjBkzADM8jBw5kptvvplXXnkFu93O0qVLcTrN55VMnTqV2bNn89JLL3HOOeeQnp7O5s3Vzw5alcLCQqZNm8Ybb7xBeHg4kZGR7Nq1ixtvvJFXXjGfJvvCCy8wZswYtm3bRnBwMC6Xi9GjR5OXl8d7771H586d2bhxIzabjcDAQK6++mrefvtt/vSnP7nPc/RzcHA9jcVwuSAv3Xwf2ZMpHyXzv+Q0ALpGBjHz+vhqZkUVERGoRRiZMGECWVlZPPnkk6SnpxMXF8fixYvdd8ekp6eTkpJSYZ+cnBzmz5/Pyy+/XDelbgLCwsL4wx/+wPvvv+8OIx9//DFhYWGMHDkSm83GWWed5d7+6aefZuHChSxatIg777zT4/Pde++97vexsbE89dRT/OUvf3GHkX/9618kJCS4PwP07t0bgLy8PF5++WX+85//cOON5mPbO3fuzDnnnONRGUpLS5kxY0aF73XBBRdU2Ob111+nZcuWLFu2jEsvvZQlS5bw66+/smnTJrp1MycD69Spk3v7W2+9laFDh5KWlkZ0dDSZmZl8/vnnlVrvzqgjh8BVCsCSvbiDyLTxfbgqIUa36YqInEKtBrDecccd3HHHHVWue+eddyotCw0NpbCwsDan8pxPgNlC4Q0+AR5tft1113HbbbcxY8YMHA4Hc+fO5eqrr8Zms1FQUMATTzzB559/TlpaGmVlZRw5cqRS0KuppUuX8s9//pONGzeSm5tLWVkZRUVFFBQUEBgYSHJycrUT0W3atIni4mJ3aKotX19f+vbtW2FZRkYGjz76KN999x0HDhzA6XRSWFjo/p7Jycm0a9fOHURONHDgQHr37s2cOXN46KGH+O9//0v79u0577zzTqusHilvFSnyDefW99YAMK5fNNcM9LwFS0SkOWp6ndcWi9lV4o2Xh49EHzt2LC6Xiy+++IK9e/eyfPlyrr/+egDuv/9+5s+fzzPPPMPy5ctJTk6mT58+lJSUnOKole3Zs4cxY8YQFxfH/PnzSUpK4tVXXwXM1goAf3//avc/2TrAPQj1+Pnzjh73xOOceNfVpEmTSEpKYvr06axcuZLk5GTCw8Pd3/NU5wazdeTtt82Hzr399tvcdNNN9ft4+jxzQPfOYrNb6NyuETxyaa/6O7+ISCPX9MJII+Lv78/48eOZO3cuH3zwAd26dSM+Ph6A5cuXM2nSJC6//HL69OlD69at3YNBPfX7779TVlbGCy+8wODBg+nWrRtpaRVbj/r27cu3335b5f5du3bF39+/2vWtWrUCzC66o5KTk2tUtuXLl3P33XczZswYevfujcPhIDMzs0K59u3bx9atW6s9xvXXX09KSgqvvPIKGzZscHclnXHOUvjwOvjoBgAOuELpHhXMuzcNJDxId4OJiNSUwoiXXXfddXzxxRe89dZb7lYRgC5durBgwQKSk5NZs2YN1157baU7b2qqc+fOlJWV8e9//5udO3fy3//+l9dee63CNlOnTuW3337jjjvuYO3atWzevJmZM2eSmZmJn58fDz74IA888ABz5sxhx44d/Pzzz7z55pvussbExPD444+zdetWvvjiC1544YUala1Lly7897//ZdOmTfzyyy9cd911FVpDhg8fznnnnccVV1xBYmIiu3bt4ssvv+Srr75yb9OyZUvGjx/P/fffz6hRo2jXrl2t6slje3+FzZ+bg6aBA0ZLRvSIxKoxIiIiHlEY8bILLriAsLAwtmzZwrXXXute/tJLL9GyZUuGDh3K2LFjufjiixkwYECtztGvXz9efPFFnnvuOeLi4pg7d26l5wh169aNb775hjVr1jBw4ECGDBnC//73P+x2c1jRI488wt///nceffRRevbsyYQJE8jIyADAx8eHDz74gM2bN3PWWWfx3HPP8fTTT9eobG+99RaHDx+mf//+TJw4kbvvvpvIyMgK28yfP5+zzz6ba665hl69evHAAw+47/I56pZbbqGkpISbb765VnVUKwcqPnU6gxZc0COymo1FRKQ6Hj8ozxv0oDw5lblz53LPPfeQlpZ20kn16vT35dM7IHmu++Oczi9yw8QzPI+OiEgjckYelCfS0BQWFrJr1y6mTZvG7bfffsrZfetUasXJ2f501cT6O7eISBOibpomYO7cuQQFBVX5OjpXSFP1r3/9i379+hEVFcXUqVPr78T5GXBwEwCLnEOY2fk1Ahz1GIRERJoQtYw0AX/84x8ZNGhQlet8fHzquTT16/HHH+fxxx+vvxO6nGb3zN5fANjg6sA9ZXfx7R+G118ZRESaGIWRJiA4OLj+pj5v7lJ+hrUfuj+ucMXxtwu70amVpnsXEamtJtNN0wjG4UoDcNq/J1nbK3xca+vNnSO6nN4xRUSauUYfRo52Q9TbdPPSqB2d2dVms9XuAAfWV/hYHDlA84qIiJymRt9NY7PZaNGihXvOi4CAgPqdClwaDZfLxcGDBwkICHDPn+Kx/esqfGwXo+fPiIicrkYfRgBat24N4A4kItWxWq20b9/e88BalANf3AcpP7kX/adsHH+Ia13HJRQRaX6aRBixWCy0adOGyMjIKh/QJnKUr6+v+8F+Hln7Eaz7CIC3reN5tvCPPHBJXwZ3Cq/jEoqIND9NIowcZbPZaj8WQORk9q8FILvtcJ7YcQVhgQ6uH9LRu2USEWkiGv0AVpF6Uf4cmpXBowELQzqH47Ar+IqI1AWFEZFTKS2C1CQAvjscAaDuGRGROqQwInIqH90AgOEIZnFaAACDY8O8WSIRkSZFYUTkZAoPwbZvANg56BkKSyE80JcukZpxVUSkriiMiJxMyk+AgRHRnef2mQ8dHBgbprlsRETqkMKIyMls/gKAlJABfLPxAAAX9YryZolERJochRGR6qyfD8lzAfiGwQAM79aKy/u39WapRESaHIURkaoUZMH/7jLfD7uXT7I6AXDtoFrM3ioiIielMCJSle1LoLQAWvUgb9hDbM3IA6B/+xbeLZeISBOkMCJSlR3fmT+7j2bFjmwMAzqGBxAZ7OfdcomINEEKIyInKiuB7Ynm+84XkLjJHLh6YU8NXBURORMURkROtGUxFGZBUGsywwbwzYbyMKK7aEREzgiFEZHjHTkMSx4z3/e/jtk/7iW/uIy4tiEM7KhZV0VEzgSFEZHjJX8Ah3dDi/Yw5E6+33IQgMnDO2O16i4aEZEzQWFE5Hipv5s/B9xANkFsOWDeRTNED8YTETljFEZEjpe6yvzZNp6fdx4CoHOrQMKDHF4slIhI06YwInLUju/g8C4AjDb9eWuF+X5E90hvlkpEpMlTGBEBOLgVPrzefN/xXNZkWfh19yF8bVZuPbeTd8smItLEKYyIAHx5vznjaodz4JoP+Oj3vQBc0rcNrUM10ZmIyJmkMCKSlgw7vweLDcbNYG+BjQWr9gFwZXw7rxZNRKQ5UBgRWTvP/Nn7cmjZgVeXbqeo1MWg2DCGdNZdNCIiZ5rCiDRvhgGbPzffx40HYPm2TADuGNFFT+gVEakHCiPSvO38HrJTwO4PnUaw73AhqdlHsFktJHRo6e3SiYg0C3ZvF0DEKwoPgcUKXz1kfh4wEXwD+GF1CgB92oYS6ND/HiIi9UH/2krzk38QXu4LpYXm58BWcP5UXC6DN1fsBOAPca29WEARkeZF3TTS/KQnHwsidj+44g0ICGPljix2HCwg2M/OdYPae7WIIiLNiVpGpPk5tPPY+8k/QkQXAOaX3857Wb9ogv18vFEyEZFmSS0j0vwcDSPD7nEHkW827OfT5FQAxg/Q3CIiIvVJYUSal19nwy+vme/DzGneDcPg/77egmHA9YPbM6C97qIREalPCiPSPLicsGI6LL7v2LLyMPLTjiy2ZeTj72PjwT/08E75RESasVqFkRkzZhAbG4ufnx/x8fEsX778pNsXFxfz8MMP06FDBxwOB507d+att96qVYFFPHZoFyy6G5Y8dmyZbxBExXG4oIS7P1wNwLj+GisiIuINHg9gnTdvHvfeey8zZsxg2LBhvP7664wePZqNGzfSvn3VdyBcddVVHDhwgDfffJMuXbqQkZFBWVnZaRde5JQ2LISPJx373H8iDLwNgqIgIIy5320jM7+ELpFBPHxJL68VU0SkObMYhmF4ssOgQYMYMGAAM2fOdC/r2bMn48aNY9q0aZW2/+qrr7j66qvZuXMnYWFhtSpkbm4uoaGh5OTkEBISUqtjSDP15ijY+4v5vv0QuPkr96riMifnPLeUg3nFTJ/Qj3H923qpkCIiTVNNr98eddOUlJSQlJTEqFGjKiwfNWoUK1eurHKfRYsWkZCQwL/+9S/atm1Lt27duO+++zhy5IgnpxbxTFkxfHLLsSACcP5DFTb5bE06B/OKaR3ix5g+beq5gCIicpRH3TSZmZk4nU6ioqIqLI+KimL//v1V7rNz505WrFiBn58fCxcuJDMzkzvuuINDhw5VO26kuLiY4uJi9+fc3FxPiikCn0+B9Z+Y7x0hcFcSBEW6V+/KLOCRT9cDcOPQjvjaNZZbRMRbajXp2YlPMjUMo9qnm7pcLiwWC3PnziU0NBSAF198kT/96U+8+uqr+Pv7V9pn2rRpPPHEE7UpmjRnhgE/TocfXoCSPHNZZC8Y/kCFILI9I58LX1wGQFigLxOHdPBCYUVE5CiP/hyMiIjAZrNVagXJyMio1FpyVJs2bWjbtq07iIA5xsQwDPbt21flPlOnTiUnJ8f92rt3ryfFlOboyGH49C+w5PFjQWT4g3DHT9D78gqbvrZsh/v9k5f1JkgPxBMR8SqP/hX29fUlPj6exMRELr/82D/wiYmJXHbZZVXuM2zYMD7++GPy8/MJCgoCYOvWrVitVtq1q3qmS4fDgcPh8KRo0lxt+QqWPw/7fju2bPS/IO5PEBheafPswhIWJacBsOCOoZrgTESkAfC4o3zKlCm88cYbvPXWW2zatIm//e1vpKSkMHnyZMBs1bjhhhvc21977bWEh4dz0003sXHjRn744Qfuv/9+br755iq7aERqJGOzOZvqBxMqBpFRT8Og2ysFEcMwmJ+0j2HPfkeJ00WvNiEKIiIiDYTH7dMTJkwgKyuLJ598kvT0dOLi4li8eDEdOpj97unp6aSkpLi3DwoKIjExkbvuuouEhATCw8O56qqrePrpp+vuW0jzcuQwvHkRFB83sHnCXOhxCVQzdunrDfv5+8dr3J+vStDzZ0REGgqP5xnxBs0zIgBsXgwbFsC6jyuvezyn2t2cLoPRL//A1gP5JHRoyVVnxzC+f1vsNt1BIyJyJtX0+q2Re9I4rPsE5t9ScVn3MbBlsTlGpBqGYfD8N1vYeiCfED87b046m1B/TfkuItKQKIxIw1RaBFu+gK4Xw7avKwaR/hOhz5XQaTgU54NvYJWH2J9TxKtLt/Pfn/cAcPvwzgoiIiINkMKINEzfPQU//Qda94Hs8lu7+18Pl74MtuN+bR1BVe6etOcQ187+heIyFwDj+7fl9vM6nelSi4hILSiMiPfkH4SPboDuo6HvVXBwC4R1grz9ZhAB2L/O/BnWCS55sWIQqYZhGExdsM4dRMICffnn+D4aIyIi0kApjIj3rHgRUlaar8RHqt4mqDXYfeGaD8F+8rlnypwuth7I58H5a9l6IJ8AXxsP/qEHA9q3xM/Hdga+gIiI1AWFEak/Lics+DPYfOHSl2Djoqq38wk0b9Md/iCEdzb3O0mLyP6cIpL2HOb5b7awK7PAvXzi4A7cOLRjHX8JERGpawojUrdKCuGX16D0CPi3gPUL4Lz7oGVHSFsN6+eb2635oPK+Q++CHpea40SOH5RaTRBxuQx+2XWI2+b8Tl5xmXt5eHm3zIU9q35EgYiINCwKI1J3DMO862XL4orLP7i66u1tvjD4DsjYCCMfg9ZxNT7V3kOFPLZoA99tznAv69M2lDdvTCDE30fdMiIijYjCiNSd7UsqB5GqtE0wB6uOnQ59/uTxaQ4VlDDu1R/JKigBzElXZ143gJE9o/DRIFURkUZHYURqzuWEbd+AxQZdLgSrFfb+Ct89DQUHzRaOE537d+g5Fj6fAmmroNsf4Np5tTr9wtX72J1ZyC+7ssgqKCEmzJ8Z18bTPiyA0ADNHyIi0lgpjEjNGAYsuA3Wf3JsWYdzYM+KytvGT4Kkd8z37YdCdH+Y8B78+joMudPjU287kMfN7/7G3kNH3MvsVgsvXdWPPu1CPT6eiIg0LAojUjNbvqwYRKDqIBLaHvrfcCyMRPUqX94WLnqyRqdK3HiAJRsPkLw3Gz9fG2v2ZldYP6xLOLed15mEjmGefQcREWmQFEakantWwu9vm3fEdB8DyXPN5UGtIX9/xW2Phozul0BAGDiCISoOHCEQ3KbGp0zem82kt38lu7C02m2W3X8+HcKrnv5dREQaJ4URMZUUwv61UJwH3zwCBzcdW/frrGPvr3jD7K4JjIDhD5gzpA7+a+Xbb29fbo4stViqPeWavdkcyC2isMTJqpTD/C85jZwjx4LIuV0jcNitLNlk3jGz9enR+No1QFVEpKlRGBHTZ/fAuo+qWGEBDPNtu4HQ8Ry4exVYrOaMqD3HVn08a/WhYUNaDr42KxNm/URRqavS+msGtmfKRd2ICPIlu7CUKR8lM7xbKwUREZEmSmGkuSkpNFs92vQvvxvmN3M69qqCSEg7mLIBNiyE9LVwzt/Mlg4f/xqfzuUyyDlSSuKmA+zIyCd5bza/7DpUYZtOrQLpF9OC7lHBXDuoPcF+x+6MaRnoy9s3Daz11xURkYZPYaS5+WKKOftpzz9Cl5Hw2b24Wz6Co+EP0+DjG83P4eVPue19ufny0Pu/pPCPhetOus3Nw2J5dGwvj48tIiJNh8JIU1OUC++OhXYJMOJhmPNHsNrNQaUuJ+z50dxu0yLzdbwJ70G7ePD5CH74P7h0es1PW+pkY3ouM5Zup2WAL7lFpXy94YB7fUyYP742K7lFZTw9Lo6Xl2xjY3oul/St+QBXERFpmhRGmprtiZCebL5cZeYA05MJ7wIt2kNEdzOIAHS72HzVwJ6sAuYn7eOD3/ZyMK+4ym3+OqIzd5zfhUCHHcMwsFgsDO4Uzr7DhfSO1jwhIiLNncJIU7AtEXJTzfk9jg8fR+f6ONElL5gPsjuSDYMmQ1CrGp3mSImT1XsP07tNKDOX7cBmhbdW7OZIqbPStn+Kb8dFvaIY0jmckOPGgFjK764J9fch1F9BREREFEYaP2cpfHQDlBaad8ScKCjKHAey4DazpQSgz1XgF3LSw7pcBvsOHyHU34fF69Mpcxms25fNR7/vq7Rt96hgxvVvS0yYP+3DAujbrkUdfDEREWkuFEYau7RkM4icqNMI81kwf3rLvB2393j45XUI73zSIFJS5uKHrQd5+dttrEvNOeXpB3cK45Vr+hMZ7HcaX0JERJozhZHG6Eg2ZG2H396ENe9XXt/5ArjuE7Daji2zWGDw5GoP+cbynfxn6faTzn4KEOBrY1BsGO3DAnj8j73d3S4iIiK1pTDS0BzYACk/Qb/rYdvXsO4TMFzm8vMfgqBIWDgZ8g9Uf4yJC2t8OpfL4NmvNjPrh53uZcEOO8O6RHDHiM5sTMtlWJcIvt6wn6yCEq45uz3twwNO5xuKiIhUYDEMw/B2IU4lNzeX0NBQcnJyCAk5+ViHRqekELYvMef8WPcJfPVQ1d0unnj85N0rhmHw8e/7mL18J3sPF1aYBTXIYeeTvwyhR+smVs8iIlLvanr9VsuIt/38Knz3dM23t/rAgBtg9wooyoYJc2Hfr9B1FHz+Nxj+YJW7GYbB7qxCnv1yE6nZR1ifmnvskBZ44aqzGNOnDcVlrgp3v4iIiJxpCiPetuP7ip+7jYayI7CzfPlNXwIWaNkBLDbzeTD+Lcxbc11OcARBzNnmtpM+dx9md2YB32zcT3QLf95asYtVKdmVTn33BV0Y3DmcmJYBxISZXS8Ou63SdiIiImeSwoi35e+v+Pm8+2HDgmNhpG28GUBOdMLzYVZsyyTE386nq9NIzS5k+bZMCksqz/8BcFZMCx4e05OBsWF18AVEREROj8KIN5UVw6HygaN9rzYHp7YdAMFR5vNjelxadRA5wTcb9nPbf5NOuo2fj5WiUhfndWvFuzedrbtgRESkwVAY8aasHeadMo4QuPw18/ZbgNB28MDOancrLnPisNswDION6bk8/On6CutHdG9FoMPObed1wukyaBPqT+tQP8qcLmxWi4KIiIg0KAoj3mIYsOkz833rPseCyCksXpfOHXNXVVput1o4u2MYd13QhaFdIqrc126z1rq4IiIiZ4rCiDek/Ayf3AK55VOr97uuys1cLoPM/GJe/nYbq1Ky8fOxsjuzoNJ2w7qEM+O6eEL9dReMiIg0Pgoj3vDbG8eCSIsOEDe+0ibrU3P4+0dr2HIgr8pD9I4OYUNaLiO6t2Lm9fH4+eguGBERaZwURuqbYcDuH83349+AXpeB3ReAtOwj/HPxJrbsz2NXZgFlrmPz0YX42Zk0tCNYLAzrHM6gTuE4XQY2q8Z/iIhI46YwUt+y90BeGljt0OMSdxBxugzufH9VhflARnRvxYSz2xPq78OQzuGVDqUgIiIiTYHCSH37+TXzZ7uB4GtONJZdWMIj/9vAqpRsAnxt/PPyPvRoE0z3qGDd+SIiIk2ewkh9yj8Iv8023w+/HzAHqd749m+s2ZsNwD/G9GRc/7ZeKqCIiEj9UxipTxsWgqsMovtD5wvYd7iQ6Uu2uYPIxMEduHZge++WUUREpJ4pjNSnNR+YP/tcRUFxGZfPWMnBvGIAHrm0F7ecE+vFwomIiHiHwkh9SV0FaavMp+72uZIlmw5wMK8YqwXevmkg53WteqIyERGRpk5TctaXjZ+aP3v9kYNGCM9/swWAv47owvBurTRQVUREmi2FkfpyeLf5s93ZzPphB3sPHSHA18aEs2O8WiwRERFvUxipL7lp5s+QtqxPzQVg6ugetGsZ4MVCiYiIeJ/CSH3JSQXACGnL5v1mGOnfvqU3SyQiItIgKIzUB2cZ5O8HINPWisOFpVgt0CUyyMsFExER8T6FkfqQlw6GC6w+rEg3F8VGBOrhdiIiItQyjMyYMYPY2Fj8/PyIj49n+fLl1W77/fffY7FYKr02b95c60I3OrlHu2iimf7tDgAu66dZVkVERKAWYWTevHnce++9PPzww6xevZpzzz2X0aNHk5KSctL9tmzZQnp6uvvVtWvXWhe60cncCkBRUAx7sgrxtVs1wZmIiEg5j8PIiy++yC233MKtt95Kz549mT59OjExMcycOfOk+0VGRtK6dWv3y2ZrRl0U+34HID2wJwBdI4MIdGi+OREREfAwjJSUlJCUlMSoUaMqLB81ahQrV6486b79+/enTZs2jBw5kqVLl5502+LiYnJzcyu8GrXdKwDYaOkGQI/WId4sjYiISIPiURjJzMzE6XQSFRVVYXlUVBT79++vcp82bdowa9Ys5s+fz4IFC+jevTsjR47khx9+qPY806ZNIzQ01P2KiWnEE4N9/TAcMseJrCgyH4LXo3WwN0skIiLSoNSqr+DEqcsNw6h2OvPu3bvTvXt39+chQ4awd+9enn/+ec4777wq95k6dSpTpkxxf87NzW28gWTjIvNn11H8mu4HFNBdYURERMTNo5aRiIgIbDZbpVaQjIyMSq0lJzN48GC2bdtW7XqHw0FISEiFV6PkcrrvpDly8QvszioAoEcbhREREZGjPAojvr6+xMfHk5iYWGF5YmIiQ4cOrfFxVq9eTZs2bTw5deOUlw6GE6x2thUG4jIgLNCXVkEOb5dMRESkwfC4m2bKlClMnDiRhIQEhgwZwqxZs0hJSWHy5MmA2cWSmprKnDlzAJg+fTodO3akd+/elJSU8N577zF//nzmz59ft9+kIcrea/4MacvmjEIAukcF6wm9IiIix/E4jEyYMIGsrCyefPJJ0tPTiYuLY/HixXTo0AGA9PT0CnOOlJSUcN9995Gamoq/vz+9e/fmiy++YMyYMXX3LRqqnPIwEhpD0u7DgLpoRERETmQxDMPwdiFOJTc3l9DQUHJychrP+JFDO+GV/gCU9ZlAv7VXkF9cxgd/HsyQzuFeLpyIiMiZV9Prt55Nc6aUT3QGsN3ejfziMtqHBTC4U5gXCyUiItLwKIycKYVZ5s/gNqwIHQtA33ahGi8iIiJyAoWRM+VoGOk5lt3ZJQB0CA/wYoFEREQaJoWRM6Ug0/wZEM6eLPNOmg5hgV4skIiISMOkMHKmHG0ZCQgn5ZAZRtqrZURERKQShZEz4eAW2GROA19gCyH18BFA3TQiIiJVURg5E9640P32neQ8ylwGsRGBRAX7ebFQIiIiDZPCyJlQnOt+uzzVnMblmcvjsFp1J42IiMiJFEbOsF2Fflgs0D+mpbeLIiIi0iApjNQ1l6vCx2yCiGkZgL+vzUsFEhERadgURupaSb777c89H6YYX7pGBnmxQCIiIg2bwkhdOzpexOrD/+wXA9CttR6OJyIiUh2FkbpWVB5GHMEkpWQD0C+mhdeKIyIi0tApjNS18pYRpyOErQfMLpv4Dhq8KiIiUh2FkbpWnAdAocWc4Cw2IpCIIIc3SyQiItKgKYzUtewUAPIww0gPjRcRERE5KYWRunRgI3wxBYBspz9gtoyIiIhI9RRG6lLS2+63OaVm1XZUGBERETkphZG6ZBjut9FF2wG1jIiIiJyKwkhdOrzL/XZpaRwAHcMVRkRERE5GYaQuZe0AYFerC3ix7Ao6twokIsjXy4USERFp2BRG6oqz1H0nzUNHJpJLELed1wmLRU/qFRERORmFkbqSnwGGE8Nq55dMszVkVK/WXi6UiIhIw6cwUleOHAagxLcFYKFTRCAtA9VFIyIicioKI3XlyCEA8i3mJGf922sKeBERkZpQGKkr5S0jmU5z5tUBHVp4sTAiIiKNh8JIXSk0W0ZSi82ZVweoZURERKRGFEbqSnnLSJYzgCCHnW5ReiaNiIhITSiM1JXyMJJNEL2iQ7BZdUuviIhITSiM1JXyAayHjSCiQvy8XBgREZHGQ2GkrhzJBiCHIMJ1S6+IiEiNKYzUlfIBrNlGkKaAFxER8YDCSF0pygYgh0AighzeLYuIiEgjojBSV0oKACgw/AhXGBEREakxhZG6UnoEgCM41E0jIiLiAYWROmK4w4ivumlEREQ8oDBSFwwDSgsBOGI4CFfLiIiISI0pjNQFZykWwwlAqdVBgK/dywUSERFpPBRG6kJ5qwgAPgHeK4eIiEgjpDBSF8rDSJlhxWZXF42IiIgnFEbqQvng1UIc+DtsXi6MiIhI46IwUhfKW0aKcOBnVxgRERHxhMJIXTh6W6/hi7+vwoiIiIgnFEbqwtHbenHg56MwIiIi4gmFkbpQ3jJShK/CiIiIiIdqFUZmzJhBbGwsfn5+xMfHs3z58hrt9+OPP2K32+nXr19tTttwHTfhmb+P8p2IiIgnPL5yzps3j3vvvZeHH36Y1atXc+655zJ69GhSUlJOul9OTg433HADI0eOrHVhG6zjpoL3V8uIiIiIRzwOIy+++CK33HILt956Kz179mT69OnExMQwc+bMk+53++23c+211zJkyJBaF7bBOi6MqJtGRETEMx6FkZKSEpKSkhg1alSF5aNGjWLlypXV7vf222+zY8cOHnvssdqVsqE7/tZehRERERGPePQQlczMTJxOJ1FRURWWR0VFsX///ir32bZtGw899BDLly/Hbq/Z6YqLiykuLnZ/zs3N9aSY9Ss3DRIfBXRrr4iISG3UarSlxWKp8NkwjErLAJxOJ9deey1PPPEE3bp1q/Hxp02bRmhoqPsVExNTm2LWjw2fut/6W0o06ZmIiIiHPAojERER2Gy2Sq0gGRkZlVpLAPLy8vj999+58847sdvt2O12nnzySdasWYPdbue7776r8jxTp04lJyfH/dq7d68nxaxfxz2LxoKBv6/uphEREfGER900vr6+xMfHk5iYyOWXX+5enpiYyGWXXVZp+5CQENatW1dh2YwZM/juu+/45JNPiI2NrfI8DocDh8PhSdG8p+TYE3v/XXY5N2vMiIiIiEc8CiMAU6ZMYeLEiSQkJDBkyBBmzZpFSkoKkydPBsxWjdTUVObMmYPVaiUuLq7C/pGRkfj5+VVa3miVD179wHUhu4w2OBRGREREPOJxGJkwYQJZWVk8+eSTpKenExcXx+LFi+nQoQMA6enpp5xzpEkpyQcg12W25GieEREREc9YDMMwvF2IU8nNzSU0NJScnBxCQkK8XZyKPp8Cv7/J9LLxTC/7E7NvSOCiXpXHz4iIiDQ3Nb1+a7Tl6SopAKDA8APA1fCznYiISIOiMHK6yrtpCjHDyIjukd4sjYiISKOjMHK6ygewFhoOXr66H752VamIiIgndOU8XeXdNIX4aSp4ERGRWlAYOV1Hx4wojIiIiNSKwsjpOtoyYjh0W6+IiEgtKIycruO6aRRGREREPKcwcrrKB7AW4NBzaURERGpBV8/T4XK5W0aOGBozIiIiUhsKI6ej7AhgTnJWgMaMiIiI1IbCyOkobxUBKMIXf1+FEREREU8pjJyOohwAco0ADKz42RVGREREPKUwcjqOZAOQYwTia7ditVq8Wx4REZFGSGHkdBRlA5BDoMaLiIiI1JLCyOk4rptGYURERKR2FEZOx5HDQHnLiAavioiI1IrCyGlwHTdmxK7xIiIiIrWiMHIa8rIPApBLINsy8r1cGhERkcZJYeQ0lOSXd9MYgYwf0NbLpREREWmcFEZOg7PADCNF9mCeuizOy6URERFpnBRGasvlIiQrGYDoqNYEOuzeLY+IiEgjpTBSW8ueI6DYHDPiE9TSy4URERFpvBRGasNZBr+/5f5YFt7Di4URERFp3BRGamPn91CQQaElkH5Fr+MX0cHbJRIREWm0FEZqY+2HAHznGEE2wbQKdni5QCIiIo2XwoinSo/Aps8B+Mw4D4CWAT7eLJGIiEijpjDiqZx9UHYEfINJKosF0J00IiIip0FhxFMFmebPwAgKSlwABCmMiIiI1JrCiKcKzTBywBXMkVInAAF6SJ6IiEitKYx4qsCcW2TtoWPjRNRNIyIiUnsKI54qyAIgywgGwGoBh13VKCIiUlu6inqqvJvmECEABPrasVgs3iyRiIhIo6Yw4qnyAaxZhhlGAhwaLyIiInI6FEY8VT5m5GgY8fdRGBERETkdCiOeKjTHjBzCHDPiMrxZGBERkcZPYcRTeekAHDRaAFDmdHmxMCIiIo2f7kmtqcN7AMPdMpJqhANQpqYRERGR06IwUhNHDsPMYVCSZ37Ej1wCAYURERGR06VumlNxuWDnMncQAdhPOGDezqtuGhERkdOjMHIqv8yEj2+ssGivM8z9Xi0jIiIip0dh5FS+/kelRS0tx1pJypwKIyIiIqdDYeRUHCGVFiW7urjf/9+VfeuzNCIiIk2OBrCeiuVYXts49jMSF77Fm2Vj+L8/9eWiXlG0CPD1YuFEREQaP7WMnExxPhRlm+8f3M0vRTG8VHYlZ3XtwJUJMQoiIiIidUBh5GRyU82fjhDWZll44rONAHRuFeTFQomIiDQtCiMnk7Xd/Bnajk+S9rkXX9QryksFEhERaXpqFUZmzJhBbGwsfn5+xMfHs3z58mq3XbFiBcOGDSM8PBx/f3969OjBSy+9VOsC1xtnKXz7JADbXa1ZuMpsJXl9YjzDukR4s2QiIiJNiscDWOfNm8e9997LjBkzGDZsGK+//jqjR49m48aNtG/fvtL2gYGB3HnnnfTt25fAwEBWrFjB7bffTmBgILfddludfIkzIn0tHNyMExt/Tr2EPKMMfx8b53Vt5e2SiYiINCkWwzA8mihj0KBBDBgwgJkzZ7qX9ezZk3HjxjFt2rQaHWP8+PEEBgby3//+t0bb5+bmEhoaSk5ODiEhlW+1PSOS3oXP7ma5M46JpeZcI7ed14l/jOlZP+cXERFp5Gp6/faom6akpISkpCRGjRpVYfmoUaNYuXJljY6xevVqVq5cyfDhw6vdpri4mNzc3AqvendgPQBb6ABAzzYh/HVEl5PtISIiIrXgURjJzMzE6XQSFVVxAGdUVBT79+8/6b7t2rXD4XCQkJDAX//6V2699dZqt502bRqhoaHuV0xMjCfFrBsHNgCwwdmeUH8fFt99DqH+PvVfDhERkSauVgNYLRZLhc+GYVRadqLly5fz+++/89prrzF9+nQ++OCDaredOnUqOTk57tfevXtrU8zaMwzYb7aMbDba06N18Cm/n4iIiNSORwNYIyIisNlslVpBMjIyKrWWnCg2NhaAPn36cODAAR5//HGuueaaKrd1OBw4HA5Pila3cvZBcQ5Oi43tRluuitS8IiIiImeKRy0jvr6+xMfHk5iYWGF5YmIiQ4cOrfFxDMOguLjYk1PXr/LxIvt9OlCKndiIQC8XSEREpOny+NbeKVOmMHHiRBISEhgyZAizZs0iJSWFyZMnA2YXS2pqKnPmzAHg1VdfpX379vTo0QMw5x15/vnnueuuu+rwa9QBlxMO74awTse6aMoHr3ZqpTAiIiJypngcRiZMmEBWVhZPPvkk6enpxMXFsXjxYjp0MC/c6enppKSkuLd3uVxMnTqVXbt2Ybfb6dy5M88++yy333573X2LurDkMVj5bxg/G9JWAZBU1BaAjuEKIyIiImeKx/OMeEO9zDPyeKj50xFiDmAtyePS4qfZZOnM5qf+gI9NM+eLiIh4oqbXb49bRpq8YnNOkxKfUDYWdaR3dIiCiIiIyBmkqyyAs6zSoh0BfXFhJaFjSy8USEREpPlQGAHITa20aH2R+QyaszuG1XdpREREmhWFEYDsPZUWrSkwW0TOimlRz4URERFpXhRGwJzk7AS7XJGE+vsQHernhQKJiIg0HwojAGVFlRalGJH0bKNp4EVERM40hREwJzwD8o1jrSBpRgQ925yh24hFRETETbf2AhguAJa5+pJlhJLv3xZnkU1hREREpB4ojIC7ZaQMO4+W3QR55uJeCiMiIiJnnLppAAwzjDhPqI4uelqviIjIGacwAu6WEdcJ1eHnY/NGaURERJoVhRE41jJiWLluUHscdit3j+zq5UKJiIg0DxozAuAyB7C6sHBRrygeHdsLh12tIiIiIvVBLSPgvpvGhRWb1aIgIiIiUo8URqDCAFabVZOciYiI1CeFEXAPYHVixW5VlYiIiNQnXXnB3TLiUsuIiIhIvVMYgQotIwojIiIi9UthBCoMYLUrjIiIiNQrhRE4btIzi1pGRERE6pnCCFS4m0YtIyIiIvVLYQQqTAdvVRgRERGpVwoj4B4z4jTUMiIiIlLfFEZAk56JiIh4kcIIHPdsGk16JiIiUt905YXjWkYsKIuIiIjUL116AUPTwYuIiHiNrryA4Sozf2rMiIiISL1TGOHElhGFERERkfqkMELFMKKWERERkfqlMAIYTj21V0RExFsURgDj6KRnWLFZFEZERETqk8IIx7ppDCyaDl5ERKSeKYxwXBix2LxcEhERkeZHYQTcD8ozrAojIiIi9U1hBNwzsFosqg4REZH6pqsvx7ppUDeNiIhIvVMYAXXTiIiIeJHCCMe3jKg6RERE6puuvnDcmBG1jIiIiNQ3hRGA8knP1E0jIiJS/xRGwD1mRANYRURE6p/CCBwLI1ZVh4iISH3T1Rfc3TRWhREREZF6p6svuAewYrF7txwiIiLNUK3CyIwZM4iNjcXPz4/4+HiWL19e7bYLFizgoosuolWrVoSEhDBkyBC+/vrrWhf4jFA3jYiIiNd4fPWdN28e9957Lw8//DCrV6/m3HPPZfTo0aSkpFS5/Q8//MBFF13E4sWLSUpKYsSIEYwdO5bVq1efduHrzNGWEataRkREROqbxTAMw5MdBg0axIABA5g5c6Z7Wc+ePRk3bhzTpk2r0TF69+7NhAkTePTRR2u0fW5uLqGhoeTk5BASEuJJcWvkyL964l+YxoNh03nu7pvq/PgiIiLNUU2v3x61jJSUlJCUlMSoUaMqLB81ahQrV66s0TFcLhd5eXmEhYV5cuozy90yolt7RURE6ptH/RKZmZk4nU6ioqIqLI+KimL//v01OsYLL7xAQUEBV111VbXbFBcXU1xc7P6cm5vrSTE9Zim/m0YzsIqIiNS/Wo3YtFgsFT4bhlFpWVU++OADHn/8cebNm0dkZGS1202bNo3Q0FD3KyYmpjbFrLmjYUQtIyIiIvXOozASERGBzWar1AqSkZFRqbXkRPPmzeOWW27ho48+4sILLzzptlOnTiUnJ8f92rt3ryfF9Jil/G4ai+6mERERqXceXX19fX2Jj48nMTGxwvLExESGDh1a7X4ffPABkyZN4v333+eSSy455XkcDgchISEVXmeSRQ/KExER8RqP72WdMmUKEydOJCEhgSFDhjBr1ixSUlKYPHkyYLZqpKamMmfOHMAMIjfccAMvv/wygwcPdreq+Pv7ExoaWodf5TSUd9PYbLq1V0REpL55fPWdMGECWVlZPPnkk6SnpxMXF8fixYvp0KEDAOnp6RXmHHn99dcpKyvjr3/9K3/961/dy2+88Ubeeeed0/8GdeBoy4jVrjAiIiJS3zyeZ8QbzvQ8I2VPtsLuKuGpLvN45Po/1PnxRUREmqMzMs9IU3W0ZcSmlhEREZF6pzACWMobh6w2DWAVERGpbwojhoEVcwCrXQNYRURE6p3CSPmdNKAwIiIi4g0KI+UTnoHGjIiIiHiDwohxLIyoZURERKT+KYwc3zLiozAiIiJS3xRGjmsZ8VHLiIiISL1TGNGYEREREa9SGDn+bhq7jxcLIiIi0jwpjBwXRnxsqg4REZH6pqtveTeN07Dg66MZWEVEROqbwkj5AFYnVrWMiIiIeIGuvuUtIy6FEREREa/Q1bdCy4jFy4URERFpfhRGXMfCiK9aRkREROqdrr4l+QAU4I+PXdUhIiJS33T1Lc4DIN/w15gRERERL9DV92gYwR+7VWNGRERE6pvCSHkYyTP88VU3jYiISL3T1bc8jBTgp24aERERL2jWV99VKYf5ft1O4OiYEXXTiIiI1LdmHUZeStzKhl37AHPMiG7tFRERqX/N+up7Yc8ogjgCQB66m0ZERMQbmvXVd2TPSIIsZhjJNzTPiIiIiDc066tvu5YBhNlLAMgnQGNGREREvKBZhxGAVr7lYcTww8fa7KtDRESk3jX7q28LaxFgDmC1atIzERGRete8w0jyB7Q7shkwx4yIiIhI/WveYWT7EvfbIkeEFwsiIiLSfNm9XQCv6jEGWnbgoF9H3j5rgrdLIyIi0iw17zASdwXEXUErb5dDRESkGWve3TQiIiLidQojIiIi4lUKIyIiIuJVCiMiIiLiVQojIiIi4lUKIyIiIuJVCiMiIiLiVQojIiIi4lUKIyIiIuJVCiMiIiLiVQojIiIi4lUKIyIiIuJVCiMiIiLiVY3iqb2GYQCQm5vr5ZKIiIhITR29bh+9jlenUYSRvLw8AGJiYrxcEhEREfFUXl4eoaGh1a63GKeKKw2Ay+UiLS2N4OBgLBZLnR03NzeXmJgY9u7dS0hISJ0dt6lSfdWc6qrmVFeeUX3VnOqq5s5UXRmGQV5eHtHR0Vit1Y8MaRQtI1arlXbt2p2x44eEhOgX1QOqr5pTXdWc6sozqq+aU13V3Jmoq5O1iBylAawiIiLiVQojIiIi4lXNOow4HA4ee+wxHA6Ht4vSKKi+ak51VXOqK8+ovmpOdVVz3q6rRjGAVURERJquZt0yIiIiIt6nMCIiIiJepTAiIiIiXqUwIiIiIl7VrMPIjBkziI2Nxc/Pj/j4eJYvX+7tItW7H374gbFjxxIdHY3FYuHTTz+tsN4wDB5//HGio6Px9/fn/PPPZ8OGDRW2KS4u5q677iIiIoLAwED++Mc/sm/fvnr8FvVj2rRpnH322QQHBxMZGcm4cePYsmVLhW1UX6aZM2fSt29f9wRKQ4YM4csvv3SvVz1Vb9q0aVgsFu699173MtXXMY8//jgWi6XCq3Xr1u71qquKUlNTuf766wkPDycgIIB+/fqRlJTkXt9g6stopj788EPDx8fHmD17trFx40bjnnvuMQIDA409e/Z4u2j1avHixcbDDz9szJ8/3wCMhQsXVlj/7LPPGsHBwcb8+fONdevWGRMmTDDatGlj5ObmureZPHmy0bZtWyMxMdFYtWqVMWLECOOss84yysrK6vnbnFkXX3yx8fbbbxvr1683kpOTjUsuucRo3769kZ+f795G9WVatGiR8cUXXxhbtmwxtmzZYvzjH/8wfHx8jPXr1xuGoXqqzq+//mp07NjR6Nu3r3HPPfe4l6u+jnnssceM3r17G+np6e5XRkaGe73q6phDhw4ZHTp0MCZNmmT88ssvxq5du4wlS5YY27dvd2/TUOqr2YaRgQMHGpMnT66wrEePHsZDDz3kpRJ534lhxOVyGa1btzaeffZZ97KioiIjNDTUeO211wzDMIzs7GzDx8fH+PDDD93bpKamGlar1fjqq6/qrezekJGRYQDGsmXLDMNQfZ1Ky5YtjTfeeEP1VI28vDyja9euRmJiojF8+HB3GFF9VfTYY48ZZ511VpXrVFcVPfjgg8Y555xT7fqGVF/NspumpKSEpKQkRo0aVWH5qFGjWLlypZdK1fDs2rWL/fv3V6gnh8PB8OHD3fWUlJREaWlphW2io6OJi4tr8nWZk5MDQFhYGKD6qo7T6eTDDz+koKCAIUOGqJ6q8de//pVLLrmECy+8sMJy1Vdl27ZtIzo6mtjYWK6++mp27twJqK5OtGjRIhISErjyyiuJjIykf//+zJ49272+IdVXswwjmZmZOJ1OoqKiKiyPiopi//79XipVw3O0Lk5WT/v378fX15eWLVtWu01TZBgGU6ZM4ZxzziEuLg5QfZ1o3bp1BAUF4XA4mDx5MgsXLqRXr16qpyp8+OGHrFq1imnTplVap/qqaNCgQcyZM4evv/6a2bNns3//foYOHUpWVpbq6gQ7d+5k5syZdO3ala+//prJkydz9913M2fOHKBh/W41iqf2nikWi6XCZ8MwKi2T2tVTU6/LO++8k7Vr17JixYpK61Rfpu7du5OcnEx2djbz58/nxhtvZNmyZe71qifT3r17ueeee/jmm2/w8/OrdjvVl2n06NHu93369GHIkCF07tyZd999l8GDBwOqq6NcLhcJCQn885//BKB///5s2LCBmTNncsMNN7i3awj11SxbRiIiIrDZbJVSXUZGRqWE2JwdHaF+snpq3bo1JSUlHD58uNptmpq77rqLRYsWsXTpUtq1a+dervqqyNfXly5dupCQkMC0adM466yzePnll1VPJ0hKSiIjI4P4+Hjsdjt2u51ly5bxyiuvYLfb3d9X9VW1wMBA+vTpw7Zt2/S7dYI2bdrQq1evCst69uxJSkoK0LD+zWqWYcTX15f4+HgSExMrLE9MTGTo0KFeKlXDExsbS+vWrSvUU0lJCcuWLXPXU3x8PD4+PhW2SU9PZ/369U2uLg3D4M4772TBggV89913xMbGVliv+jo5wzAoLi5WPZ1g5MiRrFu3juTkZPcrISGB6667juTkZDp16qT6Ooni4mI2bdpEmzZt9Lt1gmHDhlWafmDr1q106NABaGD/ZtXZUNhG5uitvW+++aaxceNG49577zUCAwON3bt3e7to9SovL89YvXq1sXr1agMwXnzxRWP16tXuW5yfffZZIzQ01FiwYIGxbt0645prrqnytq927doZS5YsMVatWmVccMEFTfI2ub/85S9GaGio8f3331e4rbCwsNC9jerLNHXqVOOHH34wdu3aZaxdu9b4xz/+YVitVuObb74xDEP1dCrH301jGKqv4/397383vv/+e2Pnzp3Gzz//bFx66aVGcHCw+99u1dUxv/76q2G3241nnnnG2LZtmzF37lwjICDAeO+999zbNJT6arZhxDAM49VXXzU6dOhg+Pr6GgMGDHDfotmcLF261AAqvW688UbDMMxbvx577DGjdevWhsPhMM477zxj3bp1FY5x5MgR48477zTCwsIMf39/49JLLzVSUlK88G3OrKrqCTDefvtt9zaqL9PNN9/s/n+rVatWxsiRI91BxDBUT6dyYhhRfR1zdB4MHx8fIzo62hg/fryxYcMG93rVVUWfffaZERcXZzgcDqNHjx7GrFmzKqxvKPVlMQzDqLt2FhERERHPNMsxIyIiItJwKIyIiIiIVymMiIiIiFcpjIiIiIhXKYyIiIiIVymMiIiIiFcpjIiIiIhXKYyIiIiIVymMiIiIiFcpjIiIiIhXKYyIiIiIVymMiIiIiFf9f3akOe2kLdUyAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# acc --> accuracy of training data, val_acc --> accuracy of test data\n",
    "losses[['accuracy','val_accuracy']].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "66b583e4-1729-4d5f-a0c5-09bec03ac1a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e34b5f9f-0f63-491c-aabc-370427ef1a5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "175/175 [==============================] - 0s 688us/step\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7bea2db2-ab16-4a90-b7cf-f215c9f6a8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(list(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e58fd3ab-9d56-4677-b006-6d7b7bf09fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = map(lambda x: np.argmax(x), predictions)\n",
    "predictions = list(predictions)\n",
    "#print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "08344e9b-c239-4109-a1d3-fe5e634acda0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.74      0.76      0.75       808\n",
      "         1.0       0.67      0.63      0.65       765\n",
      "         2.0       0.52      0.61      0.56       770\n",
      "         3.0       0.72      0.62      0.67       848\n",
      "         4.0       0.69      0.71      0.70       789\n",
      "         5.0       0.79      0.80      0.79       779\n",
      "         6.0       0.98      0.95      0.96       841\n",
      "\n",
      "    accuracy                           0.73      5600\n",
      "   macro avg       0.73      0.73      0.73      5600\n",
      "weighted avg       0.73      0.73      0.73      5600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a4052550-f15f-4928-ba5d-55e29e56fe7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#list(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5650ec31-2d8b-44a0-880c-92df6e7f5c34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[617, 101,  31,   6,  12,  33,   8],\n",
       "       [118, 484, 148,   6,   6,   2,   1],\n",
       "       [ 43, 122, 467, 111,  15,   7,   5],\n",
       "       [  5,  10, 200, 527,  98,   5,   3],\n",
       "       [  9,   1,  20,  79, 558, 122,   0],\n",
       "       [ 28,   1,   5,   6, 118, 621,   0],\n",
       "       [ 10,   2,  28,   1,   0,   1, 799]], dtype=int64)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "aa9bf158-5a16-4759-93f2-f82559cd4d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"classification_model_20000_model1_input5_600.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "913441c7-d02c-4e0c-8411-81401f786e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "model1 = load_model(\"classification_model_20000_model1_input5_600.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e6f65c94-f996-47db-9f4b-78cd1f8e0e99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\hank4\\AppData\\Local\\Temp\\tmpa3tbu0ux\\assets\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Convert the model\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model1) # path to the SavedModel directory\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save the model.\n",
    "with open('classification_model_20000_model1_input5_600.tflite', 'wb') as f:\n",
    "  f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "796b57ae-ac91-4431-96c0-c5d84894ae8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Load the TFLite model and allocate tensors.\n",
    "interpreter = tf.lite.Interpreter(model_path=\"classification_model_20000_model1_input5_600.tflite\")\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# Get input and output tensors.\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "tflite_output_data = []\n",
    "\n",
    "for i in range(len(X_test)):\n",
    "    input_data = np.array(np.expand_dims(X_test[i], axis=0), dtype=np.float32)\n",
    "    interpreter.set_tensor(input_details[0]['index'], input_data)\n",
    "    \n",
    "    interpreter.invoke()\n",
    "    \n",
    "    # The function `get_tensor()` returns a copy of the tensor data.\n",
    "    # Use `tensor()` in order to get a pointer to the tensor.\n",
    "    output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "    tflite_output_data.append(output_data)\n",
    "#print(tflite_output_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "162d1c9d-e362-48d5-8718-3965c0288cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "tflite_predictions = map(lambda x: np.argmax(x), tflite_output_data)\n",
    "tf_lite_predictions = list(tflite_predictions)\n",
    "#print(tf_lite_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4dabcc94-7103-47cb-ac4d-a928a86fb2bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[617, 101,  31,   6,  12,  33,   8],\n",
       "       [118, 484, 148,   6,   6,   2,   1],\n",
       "       [ 43, 122, 467, 111,  15,   7,   5],\n",
       "       [  5,  10, 200, 527,  98,   5,   3],\n",
       "       [  9,   1,  20,  79, 558, 122,   0],\n",
       "       [ 28,   1,   5,   6, 118, 621,   0],\n",
       "       [ 10,   2,  28,   1,   0,   1, 799]], dtype=int64)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test,tf_lite_predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
